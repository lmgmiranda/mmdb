{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMDb Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Auxiliar\n",
    "import os\n",
    "import calendar\n",
    "import datetime as dt\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "# For word frequency count\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Output\n",
    "import pickle\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting\n",
    "from IPython.core.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## APIs\n",
    "# https://imdbpy.readthedocs.io/en/latest/usage/quickstart.html\n",
    "from imdb import IMDb\n",
    "# https://pytrakt.readthedocs.io/en/latest/getstarted.html\n",
    "from trakt import init\n",
    "from trakt.users import User\n",
    "import trakt.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export settings\n",
    "path = os.getcwd()\n",
    "src_path = path + '\\\\Desktop\\\\Data Analysis\\\\jupyterlab\\\\mmdb\\\\'\n",
    "# Export pickle file\n",
    "pkl_file = 'movies.pkl'\n",
    "pkl_path = src_path + pkl_file\n",
    "# Export txt file\n",
    "txt_export = 'imdb.txt'\n",
    "txt_path = src_path + txt_export   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bool(prompt):\n",
    "    \"\"\"Get user input.\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            return {\"true\":True,\"false\":False}[input(prompt).lower()]\n",
    "        except KeyError:\n",
    "            print(\"Invalid input! Please answer True or False!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to get new data (True/False)?  false\n",
      "Do you want to export data (True/False)?  false\n"
     ]
    }
   ],
   "source": [
    "## OPTIONAL\n",
    "# Get data\n",
    "get_data = get_bool(\"Do you want to get new data (True/False)? \")\n",
    "# Export data\n",
    "export = get_bool(\"Do you want to export data (True/False)? \")\n",
    "# Check data before analysis\n",
    "data_check = False\n",
    "# Update metascore and imdbRating / imdbVotes\n",
    "update = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trakt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Trakt API parameters\n",
    "# user = ****\n",
    "# user_client_id = ****\n",
    "# user_client_secret = ****\n",
    "# pin = ****\n",
    "trakt_api_login = pd.read_csv(src_path + 'trakt_api_login.txt', sep=' = ', header=None)\n",
    "trakt_api_login.columns = ['parameters','values']\n",
    "trakt_api_login.set_index('parameters', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://trakt.docs.apiary.io/#\n",
    "# Access Trakt\n",
    "trakt.core.AUTH_METHOD = trakt.core.OAUTH_AUTH  # Set the auth method to OAuth\n",
    "# Add trakt login parameters\n",
    "user = trakt_api_login.loc['user'].values[0]\n",
    "user_client_id = trakt_api_login.loc['user_client_id'].values[0]\n",
    "user_client_secret = trakt_api_login.loc['user_client_secret'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Movies watched multiple times (between 2020 and 2022)\n",
    "# Jojo Rabbit\n",
    "# Dune (2021)\n",
    "# The Trip\n",
    "# Heavy Trip\n",
    "\n",
    "# Method 'last_watched_movies\" from pytrakt only gets last result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRAKT:\n",
    "    \"\"\"TRAKT class - Extract movie information from Trakt API and fill dataframe.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Constructor - Initialize dataframe.\"\"\"\n",
    "        self.__df = pd.DataFrame()\n",
    "        init(user, client_id=user_client_id, client_secret=user_client_secret);\n",
    "\n",
    "    def clean_id(self, x):\n",
    "        \"\"\"Clean movie id string (remove 'tt').\"\"\"\n",
    "        return x.replace('tt','')\n",
    " \n",
    "    def create_df(self, start_date='2018-01-01'):\n",
    "        \"\"\"Fill dataframe with data since 'start_date'.\"\"\"\n",
    "        # Access personal account\n",
    "        self.__my = User(user)      \n",
    "               \n",
    "        temp = [\n",
    "            [self.__my.watched_movies[i].title, \n",
    "             self.clean_id(self.__my.watched_movies[i].imdb), \n",
    "             self.__my.watched_movies[i].last_watched_at, \n",
    "             self.__my.watched_movies[i].year] \n",
    "            for i in range(len(self.__my.watched_movies))\n",
    "        ]\n",
    "       \n",
    "        # Add info to dataframe\n",
    "        self.__df = self.__df.append(temp)\n",
    "        self.__df.columns = ['title','id','timestamp','year']                        \n",
    "        self.__df.loc[:,'timestamp'] = pd.to_datetime(self.__df.timestamp, utc=True)\n",
    "        # https://stackoverflow.com/questions/55598122/pandas-adding-timezone-offset-to-the-timestamp-after-using-tz-convert\n",
    "        timezone = 'Europe/Lisbon'\n",
    "        self.__df.loc[:,'timestamp'] = self.__df.loc[:,'timestamp'].dt.tz_convert(timezone).dt.tz_localize(None)\n",
    "        self.__df = self.__df[self.__df.timestamp > pd.Timestamp(start_date)].sort_values(by='timestamp').reset_index(drop=True)\n",
    "        return self.__df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDB:\n",
    "    \"\"\"IMDb class - Extract movie information from IMDb API and fill dataframe.\"\"\"\n",
    "    # Significant keys from method 'get_movie'\n",
    "    # Do not change the names!\n",
    "    cols = ['title','year','imdbID','certificates','runtimes','genres',\n",
    "            'director','writer','cinematographer','cast','countries',\n",
    "            'languages','metascore','rating','votes','plot outline',\n",
    "            'production companies','distributors','producer','composer',\n",
    "            'box office','budget']\n",
    "\n",
    "    # Column query extract type\n",
    "    cols_info = ['runtimes','genres','countries','languages','rating','votes','plot outline']\n",
    "    cols_name = ['director','writer','cinematographer','cast','production companies','distributors','producer','composer']\n",
    "    # Numeric columns (not including year)\n",
    "    cols_numeric = ['runtimes', 'metascore', 'rating', 'votes']\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Constructor - Initialize dataframe.\"\"\"\n",
    "        self.__df = pd.DataFrame(columns=self.cols)\n",
    "        \n",
    "        # basic column types\n",
    "        self.__cols_int = ['year','runtimes','metascore','votes']\n",
    "        self.__cols_float = ['rating']\n",
    "        self.__cols_str = ['title','imdbID','certificates','genres','director','writer','cinematographer','cast','countries','languages','plot outline',\n",
    "                           'production companies','distributors','producer','composer','box office']\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "        \"\"\"Load IMDb file.\"\"\"\n",
    "        try:\n",
    "            return pd.read_csv(filename)\n",
    "        except FileNotFoundError:\n",
    "            print('File not found!', filename)\n",
    "            return 3            \n",
    "\n",
    "    def request_db(self, moviesid):\n",
    "        \"\"\"Connect with IMDb API and get movie.\"\"\"\n",
    "        all_movies = []  \n",
    "        # Create an instance of the IMDb class to access API\n",
    "        ia = IMDb()        \n",
    "        \n",
    "        for idx in moviesid:\n",
    "            search = idx.replace(r'tt', '')    \n",
    "            # Get general movie data\n",
    "            data = ia.get_movie(search)            \n",
    "            all_movies.append({key: data.get(key) for key in self.cols[:-1]}) # self.cols[:-1] don't include 'budget'\n",
    "            # Get metascore (off imdb)\n",
    "            meta = ia.get_movie_critic_reviews(search)['data']\n",
    "            all_movies[-1].update({'metascore': meta})             \n",
    "        return all_movies  \n",
    "\n",
    "    def convert_columns(self, df):\n",
    "        \"\"\"Convert columns to appropriate formats.\"\"\"\n",
    "        to_datetime = ['timestamp', 'date', 'time']\n",
    "        try:\n",
    "            df.columns = self.cols\n",
    "        except ValueError:\n",
    "            df.columns = self.cols + to_datetime\n",
    "            \n",
    "        # Clean and convert to type\n",
    "        df[self.__cols_int] = df[self.__cols_int].replace('N/A', 0).fillna(0).astype(int)\n",
    "        df[self.__cols_float] = df[self.__cols_float].astype(float)\n",
    "        df[self.__cols_str] = df[self.__cols_str].fillna('N/A').astype(str)\n",
    "        return df\n",
    "    \n",
    "    # Get values from 'keys' in need of special cleaning.\n",
    "    @staticmethod\n",
    "    def get_imdbid(x):\n",
    "        \"\"\"Need an imdbID with at least 7 digits.\"\"\"\n",
    "        return x.zfill(7)\n",
    "     \n",
    "    @staticmethod\n",
    "    def get_rated(x):\n",
    "        \"\"\"Get values from certificates - renamed to rated.\"\"\"\n",
    "        notrated = 'Not Rated'\n",
    "        try:\n",
    "            # Get United States' certificates\n",
    "            temp = [rated.split(':')[1] for rated in x if 'United States' in rated]\n",
    "            aux = ', '.join(set(temp)) # remove duplicates in string\n",
    "            if not aux: return notrated\n",
    "            else: return aux\n",
    "        except: # be careful with this...\n",
    "            return notrated\n",
    "\n",
    "    @staticmethod\n",
    "    def get_metascore(x):\n",
    "        \"\"\"Get values from metascore.\"\"\"\n",
    "        try:  \n",
    "            return x.get('metascore')\n",
    "        except (ValueError, AttributeError):  \n",
    "            return 0\n",
    "\n",
    "    @staticmethod\n",
    "    def get_boxoffice(x):\n",
    "        \"\"\"Get values from box office.\"\"\"\n",
    "        try:\n",
    "            return x.get('Cumulative Worldwide Gross').lstrip('$').split(', ')[0]\n",
    "        except (ValueError, AttributeError):  \n",
    "            return 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_budget(x):\n",
    "        \"\"\"Get budget from box office information.\"\"\"\n",
    "        try:\n",
    "            return x.get('Budget').lstrip('$').rstrip(' (estimated)')\n",
    "        except (ValueError, AttributeError):  \n",
    "            return 0\n",
    "\n",
    "    def get_info_list(self, x, cols, d):\n",
    "        \"\"\"Extract information from imdb ia object : <info>.\"\"\"\n",
    "        # x - series\n",
    "        # cols - columns\n",
    "        # d - dictionary\n",
    "        for col in cols:\n",
    "            temp = []\n",
    "            if x[col] != None:\n",
    "                d[col] = x[col]\n",
    "            else:\n",
    "                if col in self.cols_numeric:\n",
    "                    d[col] = 0\n",
    "                elif col == 'plot outline':\n",
    "                    d[col] = 'N/A'\n",
    "                else:\n",
    "                    d[col] = ['N/A']            \n",
    "        return d\n",
    "\n",
    "    def get_name_list(self, x, cols, d):\n",
    "        \"\"\"Extract information from imdb ia object : <name>.\"\"\"\n",
    "        # x - series\n",
    "        # cols - columns\n",
    "        # d - dictionary\n",
    "        for col in cols:\n",
    "            if x[col] != None:\n",
    "                temp = []\n",
    "                for info in x[col]:\n",
    "                    if info != None:\n",
    "                        temp.append(info)\n",
    "                    else:\n",
    "                        pass\n",
    "                # drop duplicates\n",
    "                # sometimes same person appears multiple times\n",
    "                if col in self.cols_name:\n",
    "                    # clean list\n",
    "                    d[col] = list(filter(None, list(set(temp))))\n",
    "                else:\n",
    "                    d[col] = list(set(temp))     \n",
    "            else:\n",
    "                d[col] = ['N/A']            \n",
    "        return d\n",
    "    \n",
    "    @staticmethod\n",
    "    def list_to_string(df, cols):\n",
    "        \"\"\"Convert column of lists into column of strings.\n",
    "        Convert value into same row != df.explode(col).\n",
    "        \"\"\"\n",
    "        for col in cols:\n",
    "            df[col] = df[col].agg(lambda x: ', '.join(map(str, x)))            \n",
    "        return df\n",
    "   \n",
    "    def clean_df(self, movies):  \n",
    "        \"\"\"Clean output from db request.\"\"\"\n",
    "        df = pd.DataFrame(columns=self.cols)    \n",
    "        # Create empty dictionaries\n",
    "        dict_info = {}\n",
    "        dict_name = {}\n",
    "\n",
    "        for movie in movies:\n",
    "            # Intiliaze list\n",
    "            temp_movie = []\n",
    "            # Set values\n",
    "            title = movie['title']\n",
    "            year = movie['year']\n",
    "            imdbid = self.get_imdbid(movie['imdbID'])\n",
    "            rated = self.get_rated(movie['certificates']) \n",
    "            metascore = self.get_metascore(movie['metascore'])\n",
    "            boxOffice = self.get_boxoffice(movie['box office'])\n",
    "            budget = self.get_budget(movie['box office'])\n",
    "            # Populate dictionaries\n",
    "            dict_info = self.get_info_list(movie, self.cols_info, dict_info)\n",
    "            dict_name = self.get_name_list(movie, self.cols_name, dict_name)\n",
    "            # Organize list according to df column order\n",
    "            temp_movie = [title, year, imdbid, rated, \n",
    "                          dict_info['runtimes'], dict_info['genres'], \n",
    "                          dict_name['director'], dict_name['writer'], dict_name['cinematographer'], dict_name['cast'],\n",
    "                          dict_info['countries'], dict_info['languages'],\n",
    "                          metascore, \n",
    "                          dict_info['rating'], dict_info['votes'], dict_info['plot outline'], \n",
    "                          dict_name['production companies'], dict_name['distributors'], dict_name['producer'], dict_name['composer'], \n",
    "                          boxOffice, budget\n",
    "                         ]   \n",
    "            # Add data to df by row\n",
    "            df.loc[len(df)] = temp_movie\n",
    "        \n",
    "        # Convert column of lists into column of strings\n",
    "        df = self.list_to_string(df, self.cols_info[:-3])\n",
    "        df = self.list_to_string(df, self.cols_name)         \n",
    "        return df\n",
    "       \n",
    "    @staticmethod\n",
    "    def movie_extra_info(moviedb, df, get):\n",
    "        \"\"\"Get movie extra info: filming locations OR keywords.\"\"\"\n",
    "        # Load file\n",
    "        path_export = src_path + get + '.txt'        \n",
    "        try:\n",
    "            df_extra_info = pd.read_csv(path_export, names=[get], header=0)\n",
    "            # Check for new movies\n",
    "            getMovies = df.shape[0] - df_extra_info.shape[0]\n",
    "            if getMovies > 0 : movieid = list(df['imdbID'].tail(getMovies))\n",
    "            else: movieid = list(df['imdbID'])     \n",
    "        except FileNotFoundError:\n",
    "            print('File not found!')\n",
    "            df_extra_info = 3\n",
    "            movieid = list(df['imdbID'])    \n",
    "                        \n",
    "        # If no df\n",
    "        if isinstance(df_extra_info, int):\n",
    "            df_extra_info = pd.DataFrame()            \n",
    "            if get == 'locations': info = [moviedb.get_movie_locations(idx).get('data').get(get) for idx in movieid]\n",
    "            elif get == 'keywords': info = [moviedb.get_movie_keywords(idx).get('data').get(get) for idx in movieid]\n",
    "            df_extra_info[get] = pd.Series(info)                \n",
    "        # If df\n",
    "        elif isinstance(df_extra_info, pd.core.frame.DataFrame):\n",
    "            if getMovies > 0:            \n",
    "                if get == 'locations': info = [moviedb.get_movie_locations(idx).get('data').get(get) for idx in movieid]\n",
    "                elif get == 'keywords': info = [moviedb.get_movie_keywords(idx).get('data').get(get) for idx in movieid] \n",
    "                # Convert string array to array\n",
    "                df_extra_info[get] = df_extra_info[get].apply(eval)   \n",
    "                df_extra_info = pd.DataFrame(pd.concat([df_extra_info[get], pd.Series(info)], ignore_index=True), columns=[get])\n",
    "            \n",
    "        # Clean the mess\n",
    "        df_extra_info[get] = df_extra_info[get].fillna('[]')  \n",
    "        return df_extra_info\n",
    "   \n",
    "    def update_imdb_values(self, df, current_year):\n",
    "        \"\"\"Update recent movies' metascore, imdbRating and imdbVotes.\"\"\"\n",
    "        # Uniform columns\n",
    "        df.columns = df.columns.str.lower()\n",
    "        # Get movies from current year\n",
    "        update = df[df.year == current_year]\n",
    "        update.rename(columns={'imdbid':'id'}, inplace=True)\n",
    "        # Get updated data and clean it\n",
    "        movies = self.request_db(update['id'])\n",
    "        movies = self.clean_df(movies)\n",
    "        # Select data to replace\n",
    "        indices = list(update.index)\n",
    "        metascore = list(movies.metascore)\n",
    "        ratings = list(movies.rating)\n",
    "        votes = list(movies.votes)\n",
    "        # Replace data\n",
    "        for i in range(len(update)):    \n",
    "            df.loc[indices[i], 'metascore'] = metascore[i]\n",
    "            df.loc[indices[i], 'imdbrating'] = ratings[i]\n",
    "            df.loc[indices[i], 'imdbvotes'] = votes[i]            \n",
    "        return df\n",
    "        \n",
    "    def df_handler(self, foo, df_trakt):\n",
    "        \"\"\"\"Check new data with existing df from pickle file.\"\"\"\n",
    "        # Check difference\n",
    "        data, newMovies = check_new_movies(foo, df_trakt) \n",
    "        # Get index\n",
    "        index = data.index        \n",
    "        # Copy foo if pickle exists and there's no new movies\n",
    "        if isinstance(foo, pd.core.frame.DataFrame):  \n",
    "            if newMovies == 0:\n",
    "                df = foo.copy()                \n",
    "            else: # newMovies != 0\n",
    "                # Request db and clean values\n",
    "                movies = self.request_db(data)\n",
    "                movies = self.clean_df(movies)                \n",
    "                # Convert to df\n",
    "                df_movies = pd.DataFrame(movies)\n",
    "                # Select last movies (from newMovies size)\n",
    "                #df_movies = df_movies.tail(newMovies).reset_index(drop=True)\n",
    "                index = index[-newMovies:]\n",
    "                # Add timestamp from trakt\n",
    "                df_movies['timestamp'] = pd.Series(df_trakt.iloc[index].reset_index()['timestamp']) \n",
    "                df_movies = from_timestamp(df_movies)     \n",
    "                # Rename columns\n",
    "                df_movies.columns = foo.columns\n",
    "                # Concatenate to original df\n",
    "                df = pd.concat([foo, df_movies], ignore_index=True)\n",
    "        # If foo don't exit\n",
    "        elif not isinstance(foo, pd.core.frame.DataFrame):\n",
    "            df = pd.DataFrame(movies)\n",
    "            # Add timestamp from trakt\n",
    "            df['timestamp'] = pd.Series(df_trakt['timestamp'])\n",
    "            df = from_timestamp(df)\n",
    "        return df.reset_index(drop=True)\n",
    "        \n",
    "    def get_imdb_data(self, src_path, newMovies, get_data, foo, df_trakt):\n",
    "        \"\"\"Load db file and connection to IMDb API.\"\"\"\n",
    "        handler = False\n",
    "        # Get data from file\n",
    "        try:\n",
    "            df = self.load(src_path + 'imdb.txt') # Load file\n",
    "            df = self.convert_columns(df) # Clean df            \n",
    "            print('DF shape: ' + str(df.shape))\n",
    "            print()        \n",
    "        except (AttributeError, OSError, IOError, TypeError) as e:\n",
    "            df = 3\n",
    "            print('No data available: ' + str(e))\n",
    "    \n",
    "        # Connection to db    \n",
    "        # Get new movies - newMovies is the difference between df and trakt data  \n",
    "        if isinstance(df, pd.core.frame.DataFrame) and newMovies > 0:\n",
    "            # Check difference\n",
    "            _, newMovies = check_new_movies(df, df_trakt)        \n",
    "            if newMovies != 0:\n",
    "                print('Adding new movies to df... \\n')\n",
    "                df = self.df_handler(df, df_trakt)\n",
    "                handler = True\n",
    "            else:\n",
    "                print('No new movies! Continue.')           \n",
    "        else:\n",
    "            if isinstance(df, pd.core.frame.DataFrame) and df.size != 0: # in case db file exist but don't want to retrieve new data\n",
    "                print('Leave IMDb alone!')\n",
    "            elif isinstance(df, int): # no files saved (get all movies)\n",
    "                if get_data:\n",
    "                    print('Get all data. \\n')\n",
    "                    # Copy foo if pickle exists and there's no new movies\n",
    "                    df = self.df_handler(foo, df_trakt)\n",
    "                    handler = True\n",
    "                else:\n",
    "                    print(\"Variable get_data == 'False'.\")\n",
    "            else:\n",
    "                print('Leave IMDb alone!')\n",
    "        \n",
    "        # If new data, convert values and prepare columns \n",
    "        if handler:       \n",
    "            # Convert and rearrange columns\n",
    "            df = self.convert_columns(df)\n",
    "            df.columns = [x.lower() for x in df.columns]    \n",
    "    \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMDb API query\n",
    "#ia = IMDb()\n",
    "#ia.get_movie_main('14821150')\n",
    "\n",
    "## Query output example\n",
    "#{'data': {'localized title': 'Vortex',\n",
    "#  'cast': [<Person id:0000783[http] name:_Dario Argento_>,\n",
    "#   <Person id:0495950[http] name:_Françoise Lebrun_>,\n",
    "# ...\n",
    "#   <Person id:2582006[http] name:_Jean-Baptiste Thoret_>],\n",
    "#  'genres': ['Drama'],\n",
    "#  'runtimes': ['142'],\n",
    "#  'countries': ['France', 'Belgium', 'Monaco'],\n",
    "#  'country codes': ['fr', 'be', 'mc'],\n",
    "#  'language codes': ['fr', 'en'],\n",
    "#  'color info': ['Color'],\n",
    "#  'aspect ratio': '1.33 : 1',\n",
    "#  'certificates': ['Argentina:18',\n",
    "#   'Canada:PG::(Alberta)',\n",
    "# ...\n",
    "#   'United Kingdom:15'],\n",
    "#  'original air date': '27 Jan 2022 (Portugal)',\n",
    "#  'rating': 7.5,\n",
    "#  'votes': 2597,\n",
    "#  'cover url': 'https://m.media-amazon.com/images/M/MV5BNjMxYTFmNTctNDgyYi00NzQwLTk1NTItMmVkYjk5Yjc1NmI2XkEyXkFqcGdeQXVyMTAyMjQ3NzQ1._V1_SY150_CR1,0,101,150_.jpg',\n",
    "#  'imdbID': '14821150',\n",
    "#  'languages': ['French', 'English'],\n",
    "#  'title': 'Vortex',\n",
    "#  'year': 2021,\n",
    "#  'kind': 'movie',\n",
    "#  'original title': 'Vortex',\n",
    "#  'director': [<Person id:0637615[http] name:_Gaspar Noé_>],\n",
    "#  'writer': [<Person id:0637615[http] name:_Gaspar Noé_>],\n",
    "#  'producer': [<Person id:1902436[http] name:_Toufik Ayadi_>,\n",
    "#   <Person id:2820211[http] name:_Christophe Barral_>,\n",
    "# ...\n",
    "#   <Person id:0917946[http] name:_Edouard Weil_>],\n",
    "#  'cinematographer': [<Person id:0213424[http] name:_Benoît Debie_>],\n",
    "#  'editor': [<Person id:1721361[http] name:_Denis Bedlow_>],\n",
    "#  'editorial department': [<Person id:10730865[http] name:_Sofiane Benabdallah_>,\n",
    "#   <Person id:1147144[http] name:_Marc Boucrot_>,\n",
    "# ...\n",
    "#   <Person id:4871217[http] name:_Kévin Laperrière_>],\n",
    "#  'production design': [<Person id:0704740[http] name:_Jean Rabasse_>],\n",
    "#  'art direction': [<Person id:12399578[http] name:_Anna Prat_>],\n",
    "#  'set decoration': [<Person id:1387131[http] name:_Nathalie Roubaud_>],\n",
    "#  'costume designer': [<Person id:0115366[http] name:_Corinne Bruand_>],\n",
    "#  'make up': [<Person id:6267423[http] name:_Joran Muratori_>],\n",
    "#  'assistant director': [<Person id:7167774[http] name:_Claire Corbetta-Doll_>,\n",
    "# ...\n",
    "#   <Person id:0701260[http] name:_David Maria Putorti_>],\n",
    "#  'art department': [<Person id:8196031[http] name:_Léopold Bossuet_>,\n",
    "#   <Person id:9223580[http] name:_Louis Boulan_>,\n",
    "# ...\n",
    "#   <Person id:9493832[http] name:_Karin Scuderi_>],\n",
    "#  'sound crew': [<Person id:0009571[http] name:_Jonathan Acbard_>,\n",
    "#   <Person id:0099125[http] name:_Bertrand Boudaud_>,\n",
    "# ...\n",
    "#   <Person id:0946675[http] name:_Ken Yasumoto_>],\n",
    "#  'visual effects': [<Person id:11269132[http] name:_Mathieu Barbe_>,\n",
    "#   <Person id:10441690[http] name:_Jérôme Battistelli_>,\n",
    "# ...\n",
    "#   <Person id:8947055[http] name:_Annabelle Zoellin_>],\n",
    "#  'stunt performer': [<Person id:2285249[http] name:_Jérôme Gaspard_>],\n",
    "#  'camera and electrical department': [<Person id:4569287[http] name:_Emmanuelle Alaitru_>,\n",
    "#   <Person id:4652245[http] name:_Julien Chassaignon_>,\n",
    "# ...\n",
    "#   <Person id:10308825[http] name:_Louis Stoltz_>],\n",
    "#  'costume department': [<Person id:7956743[http] name:_Constance Allain_>,\n",
    "#   <Person id:12598757[http] name:_Léa Peixoto_>],\n",
    "#  'music department': [<Person id:6612986[http] name:_Steve Bouyer_>,\n",
    "#   <Person id:2247261[http] name:_Pascal Mayer_>],\n",
    "#  'miscellaneous crew': [<Person id:0231270[http] name:_Laetitia Dom_>,\n",
    "#   <Person id:4378164[http] name:_François-Xavier Ecochard_>,\n",
    "#   <Person id:13433456[http] name:_Tamara Saint Léger_>],\n",
    "#  'thanks': [<Person id:8598239[http] name:_Héloïse Noé_>],\n",
    "#  'akas': ['Au bord du monde (France)',\n",
    "# ...\n",
    "#   \"Ma'arbolet (Israel, Hebrew title)\"],\n",
    "#  'production companies': [<Company id:0126452[http] name:_Rectangle Productions_>,\n",
    "#   <Company id:0889391[http] name:_Wild Bunch International_>,\n",
    "# ...\n",
    "#   <Company id:0169751[http] name:_Tax Shelter du Gouvernement Fédéral Belge_>],\n",
    "#  'distributors': [<Company id:0331328[http] name:_Picturehouse Entertainment_>,\n",
    "#   <Company id:0091802[http] name:_Xenix Filmdistribution_>,\n",
    "# ...\n",
    "#   <Company id:0747471[http] name:_Utopia_>],\n",
    "#  'special effects': [<Company id:0060901[http] name:_BUF_>],\n",
    "#  'other companies': [<Company id:0907205[http] name:_Monark_>]},\n",
    "# 'titlesRefs': {},\n",
    "# 'namesRefs': {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe styling\n",
    "# https://www.analyticsvidhya.com/blog/2021/06/style-your-pandas-dataframe-and-make-it-stunning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle():\n",
    "    \"\"\"Load pickle file.\"\"\"\n",
    "    is_pickle = False\n",
    "    # Load pickle file\n",
    "    try:\n",
    "        foo = pickle.load(open(pkl_path, \"rb\"))\n",
    "    except FileNotFoundError:\n",
    "        print('File not found!')\n",
    "        foo = 3\n",
    "    # If foo is df\n",
    "    if isinstance(foo, pd.core.frame.DataFrame):\n",
    "        is_pickle = True\n",
    "        foo.columns = foo.columns.str.lower()\n",
    "        # Convert to datetime type and sort by date\n",
    "        foo['timestamp'] = pd.to_datetime(foo['timestamp'], utc=True)\n",
    "        foo.sort_values(by='timestamp', inplace=True)\n",
    "        foo = foo.reset_index(drop=True)\n",
    "        foo.info()\n",
    "    else:\n",
    "        print('No pickle.')    \n",
    "    return foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_new_movies(foo, df_trakt):\n",
    "    \"\"\"Check if foo size is different than df_track size (new movies added).\"\"\"\n",
    "    # Initialize data\n",
    "    data = []\n",
    "    newMovies = 0\n",
    "    # If foo exist and want new data\n",
    "    if isinstance(foo, pd.core.frame.DataFrame) and get_data:              \n",
    "        # New movies - difference between df sizes\n",
    "        newMovies = len(df_trakt) - len(foo)\n",
    "        if newMovies > 0:   \n",
    "            # Select data to search in IMDb\n",
    "            data = df_trakt.iloc[-newMovies:]['id']\n",
    "    # If foo don't exist\n",
    "    elif not isinstance(foo, pd.core.frame.DataFrame):       \n",
    "        newMovies = len(df_trakt)\n",
    "        # Select data to query IMDb API\n",
    "        data = df_trakt['id']        \n",
    "    else:\n",
    "        print('Do nothing.')        \n",
    "    return data, newMovies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df, lst_cols, fill_value='', preserve_index=False):\n",
    "    \"\"\"Convert string with multiple values to array of values.\n",
    "    \n",
    "    # Example of preparation for \"exploding\"\n",
    "    # df_explode_genre.Genre = df_explode_genre.Genre.str.split(',').apply(lambda x: [e.strip() for e in x])\n",
    "    \n",
    "    # https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows\n",
    "    \"\"\"\n",
    "    # make sure 'lst_cols' is list-alike\n",
    "    if (lst_cols is not None\n",
    "        and len(lst_cols) > 0\n",
    "        and not isinstance(lst_cols, (list, tuple, np.ndarray, pd.Series))):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except 'lst_cols'\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "    # preserve original index values    \n",
    "    idx = np.repeat(df.index.values, lens)\n",
    "    # create \"exploded\" df\n",
    "    res = (pd.DataFrame({\n",
    "                col:np.repeat(df[col].values, lens)\n",
    "                for col in idx_cols},\n",
    "                index=idx)\n",
    "             .assign(**{col:np.concatenate(df.loc[lens>0, col].values)\n",
    "                            for col in lst_cols}))\n",
    "    # append those rows that have empty lists\n",
    "    if (lens == 0).any():\n",
    "        # at least one list in cells is empty\n",
    "        res = (res.append(df.loc[lens==0, idx_cols], sort=False)\n",
    "                  .fillna(fill_value))\n",
    "    # revert the original index order\n",
    "    res = res.sort_index()\n",
    "    # reset index if requested\n",
    "    if not preserve_index:        \n",
    "        res = res.reset_index(drop=True)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_date(df):\n",
    "    \"\"\"Explode date into multiple columns.\"\"\"    \n",
    "    df['Date'] = df['Timestamp'].dt.date    \n",
    "    df['DateYear'] = df['Timestamp'].dt.year    \n",
    "    df['Month'] = df['Timestamp'].dt.month\n",
    "    df['MonthName'] = df['Timestamp'].dt.month_name()    \n",
    "    df['Weekday'] = df['Timestamp'].dt.weekday\n",
    "    df['WeekdayName'] = df['Timestamp'].dt.strftime(\"%A\")    \n",
    "    df['Day'] = df['Timestamp'].dt.day    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_explode(df, col):\n",
    "    \"\"\"Split string and explode result.\"\"\"    \n",
    "    df[col] = df[col].str.split(',').apply(lambda x: [e.strip() for e in x])       \n",
    "    return explode(df, [col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_by_year(df, all_watched=False, docs=False):\n",
    "    \"\"\"Get total movies watched by year.\"\"\"\n",
    "    cols = ['Title','Genre','Director','Timestamp']\n",
    "    df_aux = df[cols].copy()\n",
    "    # Get documentaries mask\n",
    "    condition = 'Documentary'\n",
    "    mask = df_aux.Genre.str.contains(condition)\n",
    "    # Select data to analyze\n",
    "    # Want everything?\n",
    "    if all_watched:\n",
    "        df_ = df_aux.copy()\n",
    "    else:\n",
    "        if docs: df_ = df_aux[mask] # only documentaries\n",
    "        else: df_ = df_aux[~mask] # don't include documentaries\n",
    "    # Drop columns\n",
    "    # Get year\n",
    "    df_['Year'] = df_['Timestamp'].dt.year\n",
    "    df_.drop(columns='Timestamp', inplace=True)\n",
    "    # To avoid incorrect match from movies with same title (watched in the same year, like Swan Song (2021))\n",
    "    # Add 'Director' to 'Title' to create unique string\n",
    "    df_['Title'] = df_['Title'] + ' - ' + df_['Director']\n",
    "    df_.drop(columns='Director', inplace=True)    \n",
    "    # Group by Year\n",
    "    df_by_year = df_.groupby(by='Year').count()\n",
    "    # Unique and count all movies watched\n",
    "    df_by_year_uc = df_.groupby(by='Year').agg({'Title':['count']}) # 'nunique' not needed currently since the IMDb API query only returns last watched date\n",
    "    # Add total row\n",
    "    rowtotal = df_by_year_uc.sum()\n",
    "    rowtotal.name = 'All'\n",
    "    df_by_year_uc.append(rowtotal)    \n",
    "    return df_by_year, df_by_year_uc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_by_year(df, col, years, TOP=20):\n",
    "    \"\"\"Top columns values by year.\"\"\"\n",
    "    # Create dataframe\n",
    "    for year in years:\n",
    "        if year == years[0]:\n",
    "            df_counter_year = counter_display(df[df['Timestamp'].dt.year == year], col, 'Title', None).copy()\n",
    "            df_counter_year = df_counter_year.reset_index()\n",
    "            df_counter_year.columns = ['index', year]\n",
    "        else:\n",
    "            add_country = counter_display(df[df['Timestamp'].dt.year == year], col, 'Title', None).reset_index()\n",
    "            add_country.columns = ['index',year]\n",
    "            # Merge new year counter\n",
    "            df_counter_year = df_counter_year.merge(add_country, how='outer', on='index')\n",
    "    # Rearrange dataframe\n",
    "    df_counter_year.rename(columns={'index':col}, inplace=True)\n",
    "    df_counter_year.set_index(col, inplace=True)\n",
    "    df_counter_year = df_counter_year.fillna(0).astype(int)\n",
    "    \n",
    "    # Add 'All' column with sum by country\n",
    "    df_counter_year.loc[:,'All'] = df_counter_year.sum(axis=1)\n",
    "    # Show TOP countries\n",
    "    df_counter_year = df_counter_year.nlargest(TOP, 'All', keep='all')\n",
    "    show_all(df_counter_year.style.background_gradient(subset=df_counter_year.columns[:-1], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_timestamp(df):\n",
    "    \"\"\"Extract date and time from timestamp.\"\"\"\n",
    "    # Convert to datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "    df['timestamp'] = df['timestamp'].dt.tz_localize(None) # remove timezone\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    # Extract time from timestamp\n",
    "    df['time'] = [dt.datetime.time(d) for d in df['timestamp']]        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def hard_correct_movie_data(df, loc, idmovie):\n",
    "#    \"\"\"Single movie hard correct.\"\"\"\n",
    "#    temp = []\n",
    "#    response = []\n",
    "#\n",
    "#    idmovie = idmovie.replace(r'tt', '')\n",
    "#    ia = IMDb()\n",
    "#    response = ia.get_movie(idmovie, info='main')\n",
    "#    temp.append({key: response.get(key) for key in self.cols})\n",
    "#    correct = self.clean_df(temp)\n",
    "#    df.iloc[loc, :] = correct.loc[0]\n",
    "#    \n",
    "#    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_days(df, calendar, year):\n",
    "    \"\"\"Get days by month/by year without a movie watched.\"\"\"\n",
    "    # Explode df\n",
    "    df_explode = explode_date(df)\n",
    "    # Filter by year\n",
    "    df_explode = df_explode[df_explode['Timestamp'].dt.year == year]\n",
    "    # Crosstab days by month\n",
    "    df_explode = pd.crosstab(df_explode['Day'], [df_explode['Month'], df_explode['MonthName']])\n",
    "      \n",
    "    # Get days of complete months in year\n",
    "    calyear = calendar[calendar.date.dt.year == year].reset_index(drop=True)\n",
    "    days_in_months = calyear.daysinmonths\n",
    "    # Complete months this year\n",
    "    len_months = len(calyear)\n",
    "        \n",
    "    # Get month columns\n",
    "    col_months = df_explode.columns\n",
    "    # Initialize\n",
    "    no_moviedays = []\n",
    "    pct_no_moviedays = 0\n",
    "    start_month = col_months[0][0]\n",
    "    # Fill movie days by month\n",
    "    for i in range(start_month, len_months+1): # up to month 12\n",
    "        moviedays = 0\n",
    "        # Sum all days by month with 0 - False (no movies watched)\n",
    "        moviedays = df_explode[i].astype(bool).sum(axis=0)\n",
    "        # Append sum to array (sum by month)\n",
    "        no_moviedays.append(int(days_in_months[i-1] - moviedays)) # -1 because index start=0\n",
    "    \n",
    "    # Percentage of days by year without a movie watched\n",
    "    if days_in_months.sum() != 0:\n",
    "        pct_no_moviedays = int((sum(no_moviedays) / days_in_months[start_month-1:].sum()) * 100)\n",
    "    else:\n",
    "        pct_no_moviedays = 0\n",
    "        \n",
    "    print(str(year))\n",
    "    print('By month: ' + str(no_moviedays))\n",
    "    print('Total: ' + str(sum(no_moviedays)) + '/' + str(calyear[start_month-1:].daysinmonths.sum()))\n",
    "    print(str(pct_no_moviedays) + ' %')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosstab_by_year(df, index=None, year=None):\n",
    "    \"\"\"Create crosstab filtering by year.\"\"\"\n",
    "    cols = ['Title','Timestamp']\n",
    "    \n",
    "    # If year == None get all years\n",
    "    if year != None:\n",
    "        df_ = df[df['Timestamp'].dt.year == year][cols].copy()\n",
    "    else:\n",
    "        df_ = df[cols].copy()    \n",
    "    df_ = explode_date(df_)\n",
    "    \n",
    "    # Create index levels\n",
    "    if index == None:\n",
    "        multiIndex = df_['DateYear']\n",
    "    else:\n",
    "        multiIndex = [df_[index], df_[index+'Name']]\n",
    "        \n",
    "    # Create df using index and columns by type of request\n",
    "    if index == 'Weekday' or index == None:\n",
    "        return pd.crosstab(multiIndex, [df_['Month'], df_['MonthName']], margins=True)\n",
    "    elif index == 'Month':\n",
    "        return pd.crosstab(multiIndex, df_['Day'])\n",
    "    else:\n",
    "        print('Error!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_weekend(df, year=None):    \n",
    "    \"\"\"Movie ratio by movies watched on weekends vs movies watched on weekdays.\"\"\"\n",
    "    df_ = create_weekday_df(df, year)\n",
    "\n",
    "    # Create Weekdays df with weekdays\n",
    "    allweek = df_.Weekday.values #['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']    \n",
    "    df_week = pd.DataFrame(0, index=allweek, columns=['Movies'])    \n",
    "    df_week.reset_index(inplace=True)\n",
    "    df_week.rename(columns={\"index\": \"Weekday\"}, inplace=True)\n",
    "\n",
    "    # Concatenate dfs\n",
    "    df_concat = pd.concat([df_week, df_]).groupby(['Weekday']).sum().reset_index()\n",
    "    df_concat = df_concat.set_index('Weekday').loc[allweek]\n",
    "\n",
    "    # Weekdays vs Weekend\n",
    "    dropdays = allweek[1:-1] # ['Tuesday','Wednesday','Thursday','Friday','Saturday']\n",
    "    # weekdays sum\n",
    "    df_concat.loc['Monday'] += df_concat.iloc[1:5].sum()\n",
    "    # weekend sum\n",
    "    df_concat.loc['Sunday'] += df_concat.iloc[5].sum()\n",
    "    # drop unecessary columns\n",
    "    df_concat.drop(dropdays, inplace=True)\n",
    "    # rename columns\n",
    "    df_concat.rename(index={'Monday': 'Weekdays'}, inplace=True)\n",
    "    df_concat.rename(index={'Sunday': 'Weekend'}, inplace=True)\n",
    "    \n",
    "    # Get ratio\n",
    "    ratio = df_concat.reset_index()['Movies']\n",
    "    pct_ratio = ((ratio.iloc[1] / (ratio.iloc[0] + ratio.iloc[1])) * 100).astype(int)    \n",
    "    print(str(pct_ratio) + '% of the movies were watched on the weekend!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_display(df, by, col, TOP=None):\n",
    "    \"\"\"Count occurrences of string.\"\"\"\n",
    "    # Check type\n",
    "    sample = df[by].sample().values[0]\n",
    "    \n",
    "    if isinstance(sample, str):\n",
    "        series = df[by].str.split(', ').apply(lambda x: [e.strip() for e in x])\n",
    "        # Remove duplicates\n",
    "        series = series.map(lambda x: list(set(x)))\n",
    "        series = pd.Series(series.map(Counter).sum())\n",
    "    else: # list\n",
    "        series = pd.Series(df[by].value_counts())\n",
    "           \n",
    "    # Organize df to export\n",
    "    df_export = pd.DataFrame(series, columns=[col])    \n",
    "    # Show everything\n",
    "    if TOP == None: \n",
    "        return df_export.sort_values(by=col, ascending=False)\n",
    "    # Show TOP\n",
    "    else: \n",
    "        return df_export.nlargest(TOP, col, keep='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_value(df, by, get_avg, TOP=None):   \n",
    "    \"\"\"\"Average movie rating by column.\n",
    "    # If column values have multiple substrings in a string (examples: 'Genre', 'Actors', etc) use explode() to separate all values\n",
    "    \"\"\"\n",
    "    # Create df to explode by 'by'\n",
    "    df_explode = df.copy() # remove some not needed columns\n",
    "    # Split multiple persons in one string\n",
    "    df_explode[by] = df_explode[by].str.split(', ').apply(lambda x: [e.strip() for e in x])\n",
    "\n",
    "    # Remove duplicates\n",
    "    df_explode[by] = df_explode[by].map(lambda x: list(set(x)))\n",
    "    \n",
    "    # Explode df base on 'by'\n",
    "    df_explode = explode(df_explode, [by])\n",
    "    \n",
    "    df_export = df_explode.groupby(by).agg({'Title':['count','; '.join], get_avg:'mean'})\n",
    "    df_export = df_export.droplevel(0, axis=1)\n",
    "    df_export = df_export.rename(columns={'join':'Movies', 'count':'Total', 'mean':get_avg})\n",
    "    \n",
    "    # if 'imdbRating'\n",
    "    if get_avg.find('Rating') != -1:\n",
    "        df_export[get_avg] = round(df_export[get_avg], 1)\n",
    "    # else 'Runtime' or 'imdbVotes'\n",
    "    else:\n",
    "        df_export[get_avg] = df_export[get_avg].astype(int)\n",
    "    # Everything  \n",
    "    if TOP == None: \n",
    "        return df_export.sort_values('Total', ascending=False)\n",
    "    # Show TOP  \n",
    "    else: \n",
    "        return df_export.nlargest(TOP, 'Total', keep='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def director_actors(data, col, TOP):\n",
    "    \"\"\"Pair director - actor.\"\"\"\n",
    "    colList = counter_display(data, col, 'Actors', None).reset_index()['index']\n",
    "    d = {}\n",
    "\n",
    "    for i in range(len(colList)):\n",
    "        value = colList[i]        \n",
    "        d[value] = [data[data[col].str.contains(colList[i])]['Actors'].values]\n",
    "\n",
    "    return pd.DataFrame.from_dict(d, orient='index', columns=['Actors']).head(TOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movies_per_day(df, year):   \n",
    "    \"\"\"\"Check movies by day.\"\"\"\n",
    "    nMovies = df.loc[year]['Title']\n",
    "    now = pd.Timestamp('now')\n",
    "    if year == now.year:\n",
    "        lastDay = dt.date.today()\n",
    "    else:\n",
    "        lastDay = dt.date(year, 12, 31)\n",
    "    \n",
    "    firstDay = dt.date(year, 1, 1)\n",
    "    delta = lastDay - firstDay\n",
    "\n",
    "    moviesByDay = nMovies / (delta.days + 1) # 1st of January\n",
    "    print(moviesByDay.round(2), 'movies per day in', year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_rating(v, R, m, C):\n",
    "    \"\"\"Function that computes the weighted rating of each movie.\"\"\"\n",
    "    # v - votes\n",
    "    # R - Rating\n",
    "    # m - minimun number of votes\n",
    "    # C - mean\n",
    "\n",
    "    # Calculation based on the IMDB formula\n",
    "    return (v/(v+m) * R) + (m/(m+v) * C).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre columns to use in the functions below\n",
    "cols_genre = ['Genre','Title','imdbRating','Timestamp']\n",
    "\n",
    "def most_watched_genre(df, TOP, year):\n",
    "    \"\"\"Genre with most watched movies.\"\"\"\n",
    "    df_explode_genre = df[df['Timestamp'].dt.year == year][cols_genre].copy()       \n",
    "    df_explode_genre = split_explode(df_explode_genre, 'Genre')     \n",
    "    df_explode_genre_rating = get_mean_value(df_explode_genre, 'Genre', 'imdbRating')\n",
    "    \n",
    "    # print\n",
    "    show_all(df_explode_genre_rating.nlargest(TOP, 'Total', keep='all'))    \n",
    "    return df_explode_genre_rating\n",
    "\n",
    "def most_watched_genre_combo(df_, TOP, year):\n",
    "    \"\"\"Most watched genre combo.\"\"\"\n",
    "    df_genre = df_[df_['Timestamp'].dt.year == year][cols_genre].copy()\n",
    "    \n",
    "    gb_genre = df_genre.groupby(by='Genre')\n",
    "    # Genre combination with most movies, showing worst and best rated movies\n",
    "    df_genre_agg = gb_genre.agg({'imdbRating': ['min','max','mean'], \n",
    "                                 'Title': 'count'})\n",
    "    df_genre_agg.reset_index(inplace=True)\n",
    "    \n",
    "    df_genre_agg_worst = gb_genre['imdbRating'].idxmin().fillna(0).astype(int)\n",
    "    df_genre_agg[('Title','worst')] = df_genre.reindex(df_genre_agg_worst).reset_index(drop=True)['Title']\n",
    "    \n",
    "    df_genre_agg_best = gb_genre['imdbRating'].idxmax().fillna(0).astype(int)\n",
    "    df_genre_agg[('Title','best')] = df_genre.reindex(df_genre_agg_best).reset_index(drop=True)['Title']\n",
    "    \n",
    "    df_genre_agg = df_genre_agg.set_index([('Genre','')]).round(1)\n",
    "    df_genre_agg.index.rename('Genre', inplace=True)\n",
    "\n",
    "    # print\n",
    "    show_all(df_genre_agg.nlargest(TOP, [('Title','count')], keep='all'))    \n",
    "    return df_genre_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_group_info(df, cols, TOP=3):  \n",
    "    \"\"\"Double group showing count, list of movies and average rating.\"\"\"\n",
    "    # Remove top 2 countries from dataframe\n",
    "    list_remove_countries = ['United States','United Kingdom']\n",
    "    # Explode columns\n",
    "    for col in cols:\n",
    "        df = split_explode(df, col)\n",
    "        # Remove countries\n",
    "        if col == 'Country':\n",
    "            df = df[~df[col].str.contains('|'.join(list_remove_countries))]        \n",
    "        # Clean strings\n",
    "        df[col] = df[col].apply(lambda x : x.lstrip(' ').rstrip(' '))\n",
    "\n",
    "    # Group by\n",
    "    gb_df = df.groupby(cols).agg({'Title':['count','; '.join], 'imdbRating':'mean'})\n",
    "    gb_df[('imdbRating','mean')] = gb_df[('imdbRating','mean')].round(2)    \n",
    "    # Select only cases with more than 1 movie\n",
    "    gb_df = gb_df[gb_df[('Title','count')] > 1]\n",
    "    \n",
    "    # Sort values by group\n",
    "    return gb_df.groupby(level=0, group_keys=False).apply(lambda x: x.sort_values(('Title','count'), ascending=False).nlargest(TOP, ('Title','count'), keep='all')) #.head(TOP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairing(df, col, pair=2):\n",
    "    \"\"\"Common column values pairing.\"\"\"\n",
    "    list_ = df[col].apply(lambda x: x.split(','))\n",
    "    list_ = [[x.lstrip().rstrip() for x in l] for l in list_] # strip ' ' from strings\n",
    "     # Counter\n",
    "    d  = Counter()\n",
    "    for sub in list_:\n",
    "        if len(list_) < pair:\n",
    "            continue\n",
    "        sub.sort()\n",
    "        for comb in combinations(sub, pair):\n",
    "            d[comb] += 1\n",
    "\n",
    "    # Create df\n",
    "    df_pairs = pd.DataFrame.from_dict(d, orient='index').reset_index()\n",
    "    df_pairs.columns = ['Pairs','Count']\n",
    "    return df_pairs.set_index('Pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set colormap\n",
    "plot_cmap = 'YlGnBu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date related lists\n",
    "days = np.arange(1, 32, 1) # 1 to 31\n",
    "weekdays = list(calendar.day_name)\n",
    "months = list(calendar.month_name)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all(df):\n",
    "    \"\"\"Display everything.\"\"\"\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(x,y):\n",
    "    \"\"\"Add value labels to plot.\"\"\"\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i, y[i], y[i], ha = 'center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ticks_vbarplot(x, y, ax):\n",
    "    \"\"\"Add ticks to vertical bar plot.\"\"\"\n",
    "    # Plot\n",
    "    bars = ax.bar(x, y, width=0.8)\n",
    "    # Bar parameters\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        label_xpos = bar.get_x() + bar.get_width() / 2\n",
    "        ax.text(label_xpos, height+0.1, s=f'{height}', ha='center', va='bottom', fontdict={'fontsize':10})\n",
    "    # Tick parameters\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(10)\n",
    "    \n",
    "    # Axis parameters\n",
    "    start = min(x)\n",
    "    end = max(x)+1    \n",
    "    #start, end = ax.get_xlim()\n",
    "    ax.xaxis.set_ticks(np.arange(start, end))\n",
    "    #ax.tick_params(axis='x', labelsize=11)\n",
    "    ax.set_xticklabels(np.arange(start, end), rotation=90)   \n",
    "    ax.yaxis.get_major_locator().set_params(integer=True)    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_watched_movies(df_all_watched):\n",
    "    \"\"\"Plot watched movies by year.\"\"\"\n",
    "    # Select data\n",
    "    x = df_all_watched.index\n",
    "    y = df_all_watched[('Title','count')]\n",
    "    label = 'mean: ' + str(int(y.mean())) # set label to print mean value\n",
    "    # Plot\n",
    "    _, ax = plt.subplots(figsize=(len(x),6))\n",
    "    add_ticks_vbarplot(x, y, ax)    \n",
    "    plt.title('# Watched movies by Year')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('# Movies')\n",
    "    ax.axhline(y=y.mean(), color='red', ls='--', label=label)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_movies_month_by_year(df_byear):\n",
    "    \"\"\"Plot watched movies each month by year.\"\"\"\n",
    "    plot_mby = crosstab_by_year(df_byear).droplevel('Month', axis=1).drop('', axis=1).T\n",
    "    # Plot\n",
    "    ax = plot_mby.drop('All', axis=1).plot(kind='bar', stacked=True, figsize=(len(plot_mby), 6));\n",
    "    ax.bar_label(ax.containers[len(years)-2])\n",
    "    plt.title('# Watched movies by Month by Year')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('# Movies')\n",
    "    plt.legend(title='Year')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_movies_trend(df_byear):\n",
    "    \"\"\"Plot watched movies trend by year.\"\"\"\n",
    "    plot_ty = crosstab_by_year(df_byear).droplevel('Month', axis=1).drop('All').drop('', axis=1).T\n",
    "    plot_ty.iloc[:,-1] = plot_ty.iloc[:,-1].replace(0, np.nan) # replace 0 values to nan values from months yet to come, for figure purposes\n",
    "    # Plot\n",
    "    ax = plot_ty.plot(figsize=(len(plot_ty),6));\n",
    "    ax.xaxis.set_ticks(np.arange(len(plot_ty.index)))\n",
    "    ax.xaxis.set_ticklabels(plot_ty.index)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 90) \n",
    "    plt.title('# Watched movies trend by Year')\n",
    "    plt.xlabel('Months')\n",
    "    plt.ylabel('# Movies')    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_movie_genre_trend(df_trend_genre_year):\n",
    "    \"\"\"Movie genre count by release year.\"\"\"\n",
    "    plot_trend_genres = split_explode(df_trend_genre_year, 'Genre')\n",
    "    plot_trend_genres = plot_trend_genres.groupby(['Year','Genre']).agg({'Title':'count'}).sort_values(['Year','Title'], ascending=False)\n",
    "    # Select data\n",
    "    plot_ct_trend_genres = plot_trend_genres.unstack().T.reset_index().set_index('Genre').drop(['level_0'], axis=1)\n",
    "    xsize = len(plot_ct_trend_genres.columns) // 2\n",
    "    ysize = len(plot_ct_trend_genres.index) // 2\n",
    "    # Plot\n",
    "    _, ax = plt.subplots(figsize=(xsize,ysize))\n",
    "    sns.heatmap(plot_ct_trend_genres, annot=True, linewidths=.5, ax=ax)\n",
    "    ax.set_xticklabels(plot_ct_trend_genres.columns, rotation=90) \n",
    "    plt.title('Genre count by Movie Release Year')\n",
    "    plt.xlabel('Release Year')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(df, index, year):\n",
    "    \"\"\"Plot a heatmap with the numeric values in each cell.\"\"\"\n",
    "    DAYS = 31\n",
    "    MONTHS = len(months)\n",
    "\n",
    "    # Create crosstab\n",
    "    plotme = crosstab_by_year(df, index, year)\n",
    "    plotme = plotme.droplevel(0, axis=0) # Remove \"Month\" integer index\n",
    "\n",
    "    # Weekday by Month\n",
    "    if index == 'Weekday':\n",
    "        # Drop rows used to organize data and \n",
    "        plotme = plotme.iloc[:-1,:]\n",
    "        plotme = plotme.droplevel(0, axis=1).iloc[:,:-1] # Remove \"All\" column\n",
    "        \n",
    "        # If less than 12 months, append missing months\n",
    "        if len(plotme.columns) < MONTHS:           \n",
    "            # Create dataframe filled with 0 and 12 months\n",
    "            df_12months = pd.DataFrame(0, index=plotme.index.values, columns=months[len(plotme.columns):])\n",
    "            plotme = pd.concat([plotme, df_12months], join='outer', axis=1)\n",
    "            \n",
    "        # Set plot\n",
    "        ylabel = index # for plt.ylabel()\n",
    "        plt.subplots(figsize=(9,4))\n",
    "        if year != None:\n",
    "            plt.title('# Movies over ' + ylabel + ' by Month (in ' + str(year) +')')\n",
    "        else:\n",
    "            plt.title('# Movies over  ' + ylabel + ' by Month')\n",
    "        \n",
    "    # Days by Month (whole month)\n",
    "    elif index == 'Month':\n",
    "        # If less than 12 months, append missing months\n",
    "        if len(plotme.index) < MONTHS:\n",
    "            # Create dataframe filled with 0 and 12 months\n",
    "            df_12months = pd.DataFrame(0, index=months[len(plotme.index):], columns=plotme.columns.values)\n",
    "            plotme = plotme.append(df_12months)\n",
    "            \n",
    "        # Use days instead of weekdays\n",
    "        plotme = plotme.T\n",
    "        # Add missing days\n",
    "        add_rows = list(set(np.arange(1, DAYS+1, 1)) - set(plotme.index))        \n",
    "        plotme = plotme.append(pd.DataFrame(0, index=add_rows, columns=plotme.columns))\n",
    "        plotme.sort_index(inplace=True)\n",
    "        \n",
    "        # Set plot\n",
    "        ylabel = 'Day' # for plt.ylabel()\n",
    "        plt.subplots(figsize=(8,15))\n",
    "        if year != None:\n",
    "            plt.title('# Movies by Day of ' + index + ' (in ' + str(year) +')')\n",
    "        else:\n",
    "            plt.title('# Movies by Day of ' + index)\n",
    "\n",
    "    # Plot\n",
    "    # Set ticks step\n",
    "    shrink = 0.7\n",
    "    diff =  plotme.values.max() - plotme.values.min()\n",
    "    if diff < 9: step = 1\n",
    "    elif diff < 30: step = 2        \n",
    "    else: step = 5\n",
    "    # Set range\n",
    "    min_val = plotme.values.min()\n",
    "    max_val = plotme.values.max()\n",
    "    ticks = np.arange(min_val, max_val+1, step) # colorbar ticks\n",
    "    boundaries = np.arange(min_val, max_val+0.1, 0.01) # colorbar range\n",
    "    sns.heatmap(plotme, annot=True, fmt=\"d\", cbar_kws={\"shrink\":shrink, \"ticks\":ticks, \"boundaries\":boundaries})\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel(ylabel)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weekday_df(df, year):\n",
    "    \"\"\"Create week dataframe with total movies watched by weekday.\"\"\"\n",
    "    # Select 'All' column and remove 'All' row\n",
    "    df_weekday = pd.DataFrame(crosstab_by_year(df, 'Weekday', year)[('All','')]).reset_index().iloc[:-1, :] \n",
    "    # Get columns names ('Weekday' and 'WeekdayName')\n",
    "    df_weekday.columns = df_weekday.columns.droplevel(1)    \n",
    "    # Select and rename columns\n",
    "    df_weekday = df_weekday[['WeekdayName','All']]    \n",
    "    \n",
    "    return df_weekday.rename(columns={\"WeekdayName\": \"Weekday\", \"All\": \"Movies\"})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weekday_bar(df, year): \n",
    "    \"\"\"Plot # movies by weekday.\"\"\"\n",
    "    df_weekday = create_weekday_df(df, year)\n",
    "\n",
    "    # Prepare plot\n",
    "    cmap = plt.get_cmap(plot_cmap)\n",
    "    norm = plt.Normalize(df_weekday['Movies'].min(), df_weekday['Movies'].max())\n",
    "    values = df_weekday['Movies'].values\n",
    "    \n",
    "    # Plot\n",
    "    ax = plt.figure(figsize=(len(values),6)).gca()\n",
    "    sns.barplot('Weekday', 'Movies', data=df_weekday, palette=cmap(norm(values)))\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 90) \n",
    "    ax.set(ylim=(0, values.max()+values.std()))\n",
    "    ax.yaxis.get_major_locator().set_params(integer=True)\n",
    "\n",
    "    if year != None:\n",
    "        plt.title('# Watched movies by Weekday (in ' + str(year) +')')\n",
    "    else:\n",
    "        plt.title('# Watched movies by Weekday')\n",
    "    plt.ylabel('# Movies')\n",
    "    \n",
    "    for i, n in enumerate(df_weekday['Movies']):\n",
    "        plt.text(i, n+0.5, n, fontdict={'fontsize':10})\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Plot ratio\n",
    "    ratio_weekend(df, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_week_bar(df, year): \n",
    "    \"\"\"Plot watched movies by week of year.\"\"\"\n",
    "    NWEEKS = 52\n",
    "    nweeks = np.arange(1, NWEEKS+1, 1)\n",
    "    \n",
    "    cols = ['Title','Timestamp']\n",
    "    df_woy = df[cols].copy()\n",
    "    df_woy['Weekofyear'] = df_woy['Timestamp'].dt.weekofyear\n",
    "    \n",
    "    # No movies from week 53 in the beginning of the year\n",
    "    temp = df_woy[df_woy['Timestamp'].dt.year == year]\n",
    "    temp = temp[~((temp['Timestamp'].dt.month == 1) & (temp['Timestamp'].dt.weekofyear >= NWEEKS))]\n",
    "    \n",
    "    # Week starts on monday and some values may fall on week 52 or 53 of previous year\n",
    "    if df_woy[df_woy['Timestamp'].dt.year == year+1].size > 0:\n",
    "        appendthis = df_woy[df_woy['Timestamp'].dt.year == year+1][df_woy['Timestamp'].dt.weekofyear >= NWEEKS]\n",
    "        temp = temp.append(appendthis)\n",
    "        \n",
    "    # Group by\n",
    "    df_woy = temp.copy()\n",
    "    gb_woy = df_woy.groupby('Weekofyear').agg({'Title':'count'}).reset_index()    \n",
    "    # If not all weeks of year present, add them\n",
    "    add_rows = list(set(nweeks) - set(gb_woy.Weekofyear))\n",
    "    gb_woy = gb_woy.append(pd.DataFrame({'Weekofyear': add_rows, 'Title': 0}))\n",
    "    gb_woy.sort_values('Weekofyear', inplace=True)\n",
    "\n",
    "    # Prepare plot\n",
    "    cmap = plt.get_cmap(plot_cmap)\n",
    "    norm = plt.Normalize(gb_woy['Title'].min(), gb_woy['Title'].max())\n",
    "    values = gb_woy['Title'].values\n",
    "    # Convert\n",
    "    gb_woy.Weekofyear = gb_woy.Weekofyear.astype(int)\n",
    "    gb_woy.rename(columns={'Title':'# Movies'}, inplace=True)\n",
    "    \n",
    "    # Plot     \n",
    "    plotme = gb_woy.set_index('Weekofyear').T\n",
    "    xsize = NWEEKS // 2\n",
    "    plt.figure(figsize=(xsize, 2))\n",
    "    sns.heatmap(plotme, annot=True, fmt=\"d\", cbar_kws={\"orientation\": \"horizontal\", \"pad\": 0.5})    \n",
    "    plt.title('# Movies watched by Week of Year (in ' + str(year) +')')\n",
    "    plt.xlabel('Week of Year')\n",
    "    #plt.ylabel('# Movies') \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hour_month_bar(df, year):\n",
    "    \"\"\"Plot how many hours spent watching movies by month.\"\"\"\n",
    "    MONTHS = len(months)\n",
    "\n",
    "    # Group by month (get .month to maintain month order)\n",
    "    group_month = [df['Timestamp'].dt.month, df['Timestamp'].dt.month_name()]    \n",
    "    df_month = df[df['Timestamp'].dt.year==year].groupby(group_month).agg({'Runtime':'sum'}).droplevel(0, axis=0).reset_index()\n",
    "    df_month['Runtime'] = (df_month['Runtime'] / 60).astype(int)\n",
    "    df_month = df_month.rename(columns={'Timestamp':'Month'})\n",
    "\n",
    "    # If less than 12 months, append missing months\n",
    "    if len(df_month) < MONTHS:\n",
    "        df_12months = pd.DataFrame({'Month':months[now.month-MONTHS:], 'Runtime':0})\n",
    "        df_month = df_month.append(df_12months.iloc[now.month-MONTHS:,:]).reset_index(drop=True)\n",
    "            \n",
    "    # Prepare plot\n",
    "    cmap = plt.get_cmap(plot_cmap)\n",
    "    norm = plt.Normalize(df_month.Runtime.min(), df_month.Runtime.max())\n",
    "    values = df_month.Runtime.values\n",
    "\n",
    "    # Plotting\n",
    "    ax = plt.figure(figsize=(MONTHS,6)).gca()\n",
    "    sns.barplot(x='Month', y='Runtime',data=df_month, palette=cmap(norm(values)))    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 90) \n",
    "    ax.set(ylim=(0, values.max()+values.std()))\n",
    "    ax.yaxis.get_major_locator().set_params(integer=True)    \n",
    "    plt.title('# Hours by Month (in ' + str(year) +')')\n",
    "    plt.ylabel('# Hours')\n",
    "    \n",
    "    for i, n in enumerate(values):\n",
    "        plt.text(i, n+0.1, n, fontdict={'fontsize':10})\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box_swarm(x, y, data, order):\n",
    "    \"\"\"Plot swarm box plot with x based on release year or decade.\"\"\"\n",
    "    # Plot\n",
    "    xsize = len(order) / 1.5    \n",
    "    _, ax = plt.subplots(figsize=(xsize, 6))\n",
    "    ax = sns.boxplot(x, y, data=data, order=order)\n",
    "    ax = sns.swarmplot(x, y, data=data, order=order, color=\".4\")\n",
    "    # Add grid lines\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.xaxis.grid(True)\n",
    "   \n",
    "    if x == 'Year':\n",
    "        x = 'Release Year'\n",
    "        ax.set_xlabel(x)\n",
    "        \n",
    "    title = y + ' by ' + x    \n",
    "    ax.set_title(title)    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 90) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_movie_trend(df, year=None):\n",
    "    \"\"\"Plot number of movies by release year.\"\"\"\n",
    "    if year is not None:\n",
    "        plot_movies_year = df[df['Timestamp'].dt.year == year].groupby(by='Year').agg({'Title': 'count'}).reset_index().copy()\n",
    "    else:\n",
    "        plot_movies_year = df.copy()\n",
    "    \n",
    "    # Plot\n",
    "    x = plot_movies_year['Year']\n",
    "    y = plot_movies_year['Title']\n",
    "    # https://towardsdatascience.com/how-to-make-bar-and-hbar-charts-with-labels-using-matplotlib-b701ce70ba9c   \n",
    "    _, ax = plt.subplots(figsize=(30, 6))\n",
    "    add_ticks_vbarplot(x, y, ax)    \n",
    "    ax.set(ylim=(0, y.max() + y.std()))\n",
    "    \n",
    "    if year is not None:\n",
    "        plt.title('# Movies watched by Release Year (in ' + str(year) +')')\n",
    "    else:\n",
    "        plt.title('# Movies watched by Release Year')\n",
    "        \n",
    "    plt.xlabel('Release Year')\n",
    "    plt.ylabel('# Movies')    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_previous_month_stats(df, cols, TOP=5):\n",
    "    \"\"\"Plot previous month analysis.\"\"\"\n",
    "    # Plot annotation function\n",
    "    def annotation(x, axs):\n",
    "        axs[j].set_xlabel(xlabel)\n",
    "        for i, rate in enumerate(x):\n",
    "            axs[j].text(rate+0.1, i+0.1, str(rate), fontdict={'fontsize':12})\n",
    "        return axs\n",
    "    \n",
    "    # Define xlabel \n",
    "    xlabel = '%'\n",
    "    # Create decade column for last month dataframe\n",
    "    df_aux = df[['Title','Year']].copy()\n",
    "    df_aux['Decade'] = df_aux['Year'].astype(int)//10*10 # convert to decade\n",
    "    # Last month's watched movies' decade count\n",
    "    df_decade_aux = pd.DataFrame(df_aux['Decade'].value_counts(normalize=True))\n",
    "    df_decade_aux = df_decade_aux.reset_index().sort_values('index', ascending=False)\n",
    "    df_decade_aux.rename(columns={'Decade':xlabel, 'index':'Decade'}, inplace=True)\n",
    "    df_decade_aux = df_decade_aux.nlargest(TOP, xlabel, keep='all')\n",
    "    df_decade_aux[xlabel] = df_decade_aux[xlabel].mul(100).round(1)\n",
    "    df_decade_aux.set_index('Decade', inplace=True)   \n",
    "    \n",
    "    # Figure\n",
    "    subplot_size = len(cols) # get column size to resize figure\n",
    "    fig, axes = plt.subplots(1, subplot_size+1, figsize=(subplot_size*8, 4))  \n",
    "    axs = axes.ravel()\n",
    "    # Plot decade (outside of cols list)\n",
    "    j=0\n",
    "    x = df_decade_aux[xlabel]\n",
    "    y = df_decade_aux.index.astype(str) # to order by greater count value and not decade (int)\n",
    "    sns.barplot(x, y, orient='h', palette=sns.color_palette('cool'), ax=axs[j])\n",
    "    axs[j].set_title('Release Decade' + ' (top ' + str(TOP) + ')')\n",
    "    axs[j].set_ylabel('Decade')\n",
    "    annotation(x, axs)    \n",
    "    # Plot col subplot\n",
    "    for j, col in enumerate(cols, start=1):\n",
    "        # Create last month cols dataframe\n",
    "        df_subplots= df[cols].copy()\n",
    "        # Explode col in order to count values\n",
    "        df_subplots[col] = df_subplots[col].str.split(',').apply(lambda x: [e.strip() for e in x])\n",
    "        df_subplots = explode(df_subplots, [col])             \n",
    "        # Count and convert to %\n",
    "        plot_subplots = pd.DataFrame(df_subplots[col].value_counts(normalize=True))\n",
    "        plot_subplots.rename(columns={col:xlabel}, inplace=True)    \n",
    "        plot_subplots = plot_subplots.nlargest(TOP, xlabel, keep='first')\n",
    "        plot_subplots[xlabel] = plot_subplots[xlabel].mul(100).round(1)        \n",
    "        # Plot subplot\n",
    "        x = plot_subplots[xlabel]\n",
    "        y = plot_subplots.index     \n",
    "        sns.barplot(x, y, orient='h', palette=sns.color_palette('cool'), ax=axs[j])\n",
    "        axs[j].set_title(str(col) + ' (top ' + str(TOP) + ')')\n",
    "        axs[j].set_ylabel(col)\n",
    "        annotation(x, axs)\n",
    "    \n",
    "    fig.suptitle(\"Previous Month Analysis\")\n",
    "    fig.tight_layout() # separation between subplots\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
