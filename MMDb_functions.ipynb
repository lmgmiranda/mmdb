{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMDb Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting\n",
    "from IPython.core.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## APIs\n",
    "# https://imdbpy.readthedocs.io/en/latest/usage/quickstart.html\n",
    "from imdb import IMDb\n",
    "\n",
    "# https://pytrakt.readthedocs.io/en/latest/getstarted.html\n",
    "from trakt import init\n",
    "from trakt.users import User\n",
    "\n",
    "import trakt.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trakt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://trakt.docs.apiary.io/#\n",
    "# Access Trakt\n",
    "trakt.core.AUTH_METHOD = trakt.core.OAUTH_AUTH  # Set the auth method to OAuth\n",
    "# Add trakt login parameters\n",
    "user = ''\n",
    "user_client_id = ''\n",
    "user_client_secret = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAKT class\n",
    "class TRAKT:\n",
    "    # Initialize dataframe and connect to trakt api\n",
    "    def __init__(self):\n",
    "        self.__df = pd.DataFrame()\n",
    "        init(user, client_id=user_client_id, client_secret=user_client_secret);\n",
    "\n",
    "    # Populate trakt dataframe with data since 'start_date'\n",
    "    def create_df(self, start_date='2018-01-01'):\n",
    "        # Access personal account\n",
    "        self.__my = User(user)      \n",
    "               \n",
    "        temp = [\n",
    "            [self.__my.watched_movies[i].title, \n",
    "             self.__my.watched_movies[i].imdb, \n",
    "             self.__my.watched_movies[i].last_watched_at, \n",
    "             self.__my.watched_movies[i].year] \n",
    "            for i in range(len(self.__my.watched_movies))\n",
    "        ]\n",
    "        \n",
    "        timezone = 'Europe/Lisbon'\n",
    "        \n",
    "        # Add info to dataframe\n",
    "        self.__df = self.__df.append(temp)\n",
    "        self.__df.columns = ['title','id','timestamp','year']\n",
    "                        \n",
    "        self.__df.loc[:,'timestamp'] = pd.to_datetime(self.__df.timestamp, utc=True)\n",
    "        # https://stackoverflow.com/questions/55598122/pandas-adding-timezone-offset-to-the-timestamp-after-using-tz-convert\n",
    "        self.__df.loc[:,'timestamp'] = self.__df.loc[:,'timestamp'].dt.tz_convert(timezone).dt.tz_localize(None)\n",
    "        self.__df = self.__df[self.__df.timestamp > pd.Timestamp(start_date)].sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "        return self.__df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key from Datacamp\n",
    "# https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=7\n",
    "apiKey = '72bc447a'\n",
    "data_URL = 'http://www.omdbapi.com/?apikey='+apiKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMDb class\n",
    "class OMDB:\n",
    "    # Initialize dataframe \n",
    "    def __init__(self):\n",
    "        self.__df = pd.DataFrame()\n",
    "\n",
    "    # Load OMDb file      \n",
    "    def load(self, filename):\n",
    "        return pd.read_csv(filename)\n",
    "       \n",
    "    # Convert 'N/A' data from int columns  \n",
    "    def convert_to_int(self, x):\n",
    "        # clean 'Year','Runtime','Metascore','imdbVotes'\n",
    "        x = x.fillna(0)\n",
    "        return x.replace('N/A', 0, regex=True).astype(int)\n",
    "\n",
    "    ##\n",
    "    # Correction and convertion of different columns \n",
    "    @staticmethod\n",
    "    def convert_rated(x):\n",
    "        return x.fillna('N/A').astype(str)\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_imdb_rating(x):\n",
    "        return x.apply(pd.to_numeric, errors='coerce').astype(float)\n",
    "    \n",
    "    def convert_imdb_votes(self, x):\n",
    "        # remove ',' from votes (ex: 6,000 to 6000)\n",
    "        return self.convert_to_int(x.astype(str).str.replace(',',''))\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_imdb_id(x):\n",
    "        # only numeric ID to join\n",
    "        return x.astype(str).str.replace('tt','')\n",
    "    \n",
    "    def convert_runtime(self, x):\n",
    "        # remove 'min', get only integers\n",
    "        return self.convert_to_int(x.astype(str).replace('N/A', '000 min', regex=True).str.replace(r'\\D', ''))\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_timestamp(x):\n",
    "        # remove timezone\n",
    "        return pd.to_datetime(x) #.apply(lambda x: x.replace(tzinfo=None))\n",
    "\n",
    "    def convert_boxoffice(self, x):\n",
    "        # clean box office values\n",
    "        return self.convert_to_int(x.astype(str).str.lstrip('$').str.replace(',',''))\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_country(x):\n",
    "        # convert country names\n",
    "        replace_country = {\n",
    "            'United Kingdom':'UK',\n",
    "            'United States':'USA'\n",
    "        }\n",
    "        return x.replace(replace_country, regex=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_language(x):\n",
    "        # convert language names\n",
    "        replace_lang = {\n",
    "            'American Sign Language':'American Sign',\n",
    "            'American Sign':'American Sign Language',\n",
    "            'Korean Sign':'Korean Sign Language'\n",
    "        }\n",
    "        return x.replace(replace_lang, regex=True)\n",
    "    \n",
    "    # Convert columns to appropriate formats\n",
    "    def convert_columns(self, df):\n",
    "        df['rated'] = self.convert_rated(df['rated'])\n",
    "        df['runtime'] = self.convert_runtime(df['runtime'])\n",
    "        df['language'] = self.convert_language(df['language'])\n",
    "        df['country'] = self.convert_country(df['country'])\n",
    "        df['metascore'] = self.convert_to_int(df['metascore'])\n",
    "        df['imdbrating'] = self.convert_imdb_rating(df['imdbrating'])\n",
    "        df['imdbvotes'] = self.convert_imdb_votes(df['imdbvotes'])\n",
    "        df['imdbid'] = self.convert_imdb_id(df['imdbid'])\n",
    "        df['timestamp'] = self.convert_timestamp(df['timestamp'] )   \n",
    "        \n",
    "        if 'date' in df.columns:\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            \n",
    "        return df\n",
    "            \n",
    "    # Connect with OMDb API\n",
    "    def request_db(self, df):        \n",
    "        response = []\n",
    "        movies = []\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            params = {}\n",
    "            movieID = df.iloc[i]['id']\n",
    "\n",
    "            params = {\n",
    "                'type':'movie',\n",
    "                'i':movieID\n",
    "            }\n",
    "            \n",
    "            movies.append(requests.get(data_URL, params=params).json())\n",
    "        \n",
    "        return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries\n",
    "testing = False\n",
    "\n",
    "if testing:\n",
    "    # single movie request\n",
    "    stitle = \"Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb\"\n",
    "    idd = 'tt3581652'\n",
    "    \n",
    "    params = {\n",
    "        #'t':stitle,\n",
    "        'type':'movie',\n",
    "        #'y': 2021 #syear\n",
    "        'i':idd\n",
    "    }\n",
    "    \n",
    "    responseTest = requests.get(data_URL, params=params).json()\n",
    "    print(responseTest)\n",
    "\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract these columns\n",
    "# don't change this in order to get correct info from imdb api\n",
    "cols_imdb = ['title','year','imdbID','runtimes','genres','director','writer','cinematographer','cast','countries','languages','rating','votes','plot outline','production companies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDb class\n",
    "class IMDB:\n",
    "    # Initialize dataframe \n",
    "    def __init__(self):\n",
    "        self.__df = pd.DataFrame(columns=cols_imdb)\n",
    "        \n",
    "        self.__cols_int = ['year','runtimes','votes']\n",
    "        self.__cols_str = ['imdbid','genres','director','writer','cinematographer','cast','countries','languages','production companies']\n",
    "    \n",
    "    # Load IMDb file      \n",
    "    def load(self, filename):\n",
    "        return pd.read_csv(filename)\n",
    "       \n",
    "    # Convert columns to appropriate formats\n",
    "    def convert_columns(self, df):\n",
    "        df[self.__cols_int] = df[self.__cols_int].replace('N/A', 0).astype(int) #.fillna(0).astype(int)\n",
    "        df[self.__cols_str] = df[self.__cols_str].fillna('N/A').astype(str)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    # Extract information from imdb ia object : <info>\n",
    "    @staticmethod    \n",
    "    def get_info_list(x, cols, d):        \n",
    "        # x - series\n",
    "        # cols - columns\n",
    "        # d - dictionary\n",
    "        for i in range(len(cols)):\n",
    "            if x[cols[i]] != None:\n",
    "                d[cols[i]] = x[cols[i]]\n",
    "            else:\n",
    "                if (cols[i] == 'rating') or (cols[i] == 'votes'):\n",
    "                    d[cols[i]] = 0\n",
    "                elif cols[i] == 'plot outline':\n",
    "                    d[cols[i]] = 'N/A'\n",
    "                else:\n",
    "                    d[cols[i]] = ['N/A']            \n",
    "        return d\n",
    "\n",
    "    # Extract information from imdb ia object : <name>\n",
    "    @staticmethod\n",
    "    def get_name_list(x, cols, d):\n",
    "        # x - series\n",
    "        # cols - columns\n",
    "        # d - dictionary\n",
    "        for i in range(len(cols)):\n",
    "            if x[cols[i]] != None:\n",
    "                temp = []\n",
    "                for info in x[cols[i]]:\n",
    "                    if info != None:\n",
    "                        temp.append(info)\n",
    "                    else:\n",
    "                        pass\n",
    "                # sometimes same person appears multiple times\n",
    "                if cols[i] == 'writer':\n",
    "                    # clean list\n",
    "                    d[cols[i]] = list(filter(None, list(set(temp))))\n",
    "                else:\n",
    "                    d[cols[i]] = temp         \n",
    "            else:\n",
    "                d[cols[i]] = ['N/A']            \n",
    "        return d\n",
    "\n",
    "    # Clean output from db request    \n",
    "    def clean_df(self, movies):  \n",
    "        df = pd.DataFrame(columns=cols_imdb)\n",
    "        \n",
    "        # columns\n",
    "        cols_info = ['runtimes','genres','countries','languages','rating','votes','plot outline']\n",
    "        cols_name = ['director','writer','cinematographer','cast','production companies']\n",
    "    \n",
    "        # dictionaries\n",
    "        dict_info = {}\n",
    "        dict_name = {}\n",
    "        \n",
    "        for i in range(len(movies)):\n",
    "            # intiliaze\n",
    "            temp_movie = []\n",
    "            movie = movies[i]\n",
    "\n",
    "            # set values\n",
    "            title = movie['title']\n",
    "            year = movie['year']\n",
    "            imdbID = movie['imdbID']\n",
    "            \n",
    "            dict_info = self.get_info_list(movie, cols_info, dict_info)\n",
    "            dict_name = self.get_name_list(movie, cols_name, dict_name)\n",
    "    \n",
    "            # organize columns according to DF\n",
    "            temp_movie = [title, year, imdbID, \n",
    "                          dict_info['runtimes'], dict_info['genres'], \n",
    "                          dict_name['director'], dict_name['writer'],\n",
    "                          dict_name['cinematographer'], dict_name['cast'],\n",
    "                          dict_info['countries'], dict_info['languages'], \n",
    "                          dict_info['rating'], dict_info['votes'], \n",
    "                          dict_info['plot outline'], dict_name['production companies']\n",
    "                         ]\n",
    "        \n",
    "            df.loc[len(df)] = temp_movie\n",
    "       \n",
    "        df = list_to_string(df, cols_info[:-3])\n",
    "        df = list_to_string(df, cols_name)    \n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Connect with IMDb API\n",
    "    def request_db(self, movies): #, ids=False):\n",
    "        all_movies = []  \n",
    "        \n",
    "        # Create an instance of the IMDb class to access API\n",
    "        ia = IMDb()        \n",
    "\n",
    "        for i in range(len(movies)):\n",
    "            search = []\n",
    "            \n",
    "            temp = ia.get_movie(movies.iloc[i]['id'].replace(r'tt', ''))            \n",
    "            # gather data to export\n",
    "            all_movies.append({key: temp.get(key) for key in cols_imdb})\n",
    "            \n",
    "        return all_movies  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe styling\n",
    "# https://www.analyticsvidhya.com/blog/2021/06/style-your-pandas-dataframe-and-make-it-stunning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two main dataframes\n",
    "def merge_dfs(df_omdb, df_imdb):\n",
    "    ## Prepare key to merge (remove tt from id and always get 7 numbers)\n",
    "    # OMDb format imdb id \n",
    "    df_omdb['imdbid'] = df_omdb['imdbid'].str.replace(r'tt', '')\n",
    "    df_omdb['imdbid'] = df_omdb['imdbid'].str.zfill(7)\n",
    "    # IMDb format imdb id \n",
    "    df_imdb['imdbid'] = df_imdb['imdbid'].str.replace(r'tt', '')\n",
    "    df_imdb['imdbid'] = df_imdb['imdbid'].str.zfill(7)\n",
    "    \n",
    "    # Merge dataframes on key = 'imdbid'\n",
    "    df_merge = df_imdb.merge(df_omdb, on='imdbid')\n",
    "    \n",
    "    # Select columns after merge\n",
    "    merge_cols = ['title_x','year_x','imdbid','rated','runtimes','genres','director_x','writer_x','cinematographer',\n",
    "                  'cast','plot','languages','countries','metascore','rating','votes','production companies',\n",
    "                  'timestamp_y','date_y','time_y']   \n",
    "    \n",
    "    df_merge = df_merge[merge_cols]\n",
    "\n",
    "    # Rename columns\n",
    "    cols = ['Title','Year','imdbID','Rated','Runtime','Genre','Director','Writer','Cinematographer',\n",
    "            'Actors','Plot','Language','Country','Metascore','imdbRating','imdbVotes','Production',\n",
    "            'Timestamp','Date','Time']   \n",
    "    \n",
    "    df_merge.columns = cols\n",
    "    \n",
    "    # Drop duplicates\n",
    "    df_merge.drop_duplicates(['Title','Year','Date'], keep='first', inplace=True)\n",
    "    # Sort by timestamp\n",
    "    df_merge.sort_values(by='Timestamp', inplace=True)\n",
    "    df_merge.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of preparation for \"exploding\"\n",
    "# Convert string with multiple values to array of values\n",
    "# df_explode_genre.Genre = df_explode_genre.Genre.str.split(',').apply(lambda x: [e.strip() for e in x])\n",
    "\n",
    "# https://stackoverflow.com/questions/12680754/split-explode-pandas-dataframe-string-entry-to-separate-rows\n",
    "def explode(df, lst_cols, fill_value='', preserve_index=False):\n",
    "    # make sure `lst_cols` is list-alike\n",
    "    if (lst_cols is not None\n",
    "        and len(lst_cols) > 0\n",
    "        and not isinstance(lst_cols, (list, tuple, np.ndarray, pd.Series))):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "    # preserve original index values    \n",
    "    idx = np.repeat(df.index.values, lens)\n",
    "    # create \"exploded\" DF\n",
    "    res = (pd.DataFrame({\n",
    "                col:np.repeat(df[col].values, lens)\n",
    "                for col in idx_cols},\n",
    "                index=idx)\n",
    "             .assign(**{col:np.concatenate(df.loc[lens>0, col].values)\n",
    "                            for col in lst_cols}))\n",
    "    # append those rows that have empty lists\n",
    "    if (lens == 0).any():\n",
    "        # at least one list in cells is empty\n",
    "        res = (res.append(df.loc[lens==0, idx_cols], sort=False)\n",
    "                  .fillna(fill_value))\n",
    "    # revert the original index order\n",
    "    res = res.sort_index()\n",
    "    # reset index if requested\n",
    "    if not preserve_index:        \n",
    "        res = res.reset_index(drop=True)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode date into multiple columns\n",
    "def explode_date(df):\n",
    "    df['DateYear'] = df['Date'].dt.year\n",
    "    \n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['MonthName'] = df['Date'].dt.month_name()\n",
    "    \n",
    "    df['Weekday'] = df['Date'].dt.weekday\n",
    "    df['WeekdayName'] = df['Date'].dt.strftime(\"%A\")\n",
    "    \n",
    "    df['Day'] = df['Date'].dt.day\n",
    "    #df.drop(columns='Date', inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_explode(df, col):\n",
    "    df[col] = df[col].str.split(',').apply(lambda x: [e.strip() for e in x])\n",
    "    df = explode(df, [col])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column of lists into column of strings\n",
    "def list_to_string(df, cols):\n",
    "    for i in range(len(cols)):\n",
    "        df[cols[i]] = df[cols[i]].agg(lambda x: ', '.join(map(str, x)))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total movies watched by Year\n",
    "def totals_by_year(df, all_watched=False, docs=False):\n",
    "    df = df[['Title','Genre','Director','Date']].copy()\n",
    "    # Get documentaries\n",
    "    df_genres = df.Genre.str.contains('Documentary')\n",
    "    \n",
    "    if all_watched:\n",
    "        df_ = df.copy()\n",
    "    else:\n",
    "        if docs:\n",
    "            df_ = df[df_genres] # include documentaries\n",
    "        else:\n",
    "            df_ = df[~df_genres] # do not include documentaries\n",
    "\n",
    "    # Get year\n",
    "    df_['Year'] = df_['Date'].dt.year\n",
    "    df_.drop(columns='Date', inplace=True)\n",
    "    # To avoid incorrect match from movies with same title (watched in the same year, like Swan Song (2021))\n",
    "    # Add 'Director' to 'Title' to create unique string\n",
    "    df_['Title'] = df_['Title'] + ' - ' + df_['Director']\n",
    "    df_.drop(columns='Director', inplace=True)\n",
    "    \n",
    "    # Group by Year\n",
    "    df_by_year = df_.groupby(by='Year').count()\n",
    "    # Unique and count all movies watched\n",
    "    df_by_year_uc = df_.groupby(by='Year').agg({'Title':['nunique','count']})\n",
    "    \n",
    "    # Add total row\n",
    "    rowtotal = df_by_year_uc.sum()\n",
    "    rowtotal.name = 'All'\n",
    "    df_by_year_uc.append(rowtotal)\n",
    "    \n",
    "    return df_by_year, df_by_year_uc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if foo size is different than df_track size (new movies viewed)\n",
    "def check_new_movies(foo, df_trakt):\n",
    "    data = []\n",
    "    newMovies = 0\n",
    "    cols = ['title','year']\n",
    "        \n",
    "    if isinstance(foo, pd.core.frame.DataFrame) and get_data:\n",
    "        # df columns as lowercase in order to compare\n",
    "        foo.columns = [x.lower() for x in foo.columns]\n",
    "        # last date in the dataset\n",
    "        last_date = foo['date'].dt.date.max()\n",
    "        # new movies since dataset's last date\n",
    "        newMovies = len(df_trakt[df_trakt['timestamp'].dt.date > last_date])\n",
    "    \n",
    "        # get added movies\n",
    "        if newMovies > 0:   \n",
    "            diffMovies = list(set(df_trakt['id']) - set(foo['imdbid']))\n",
    "            df_diffMovies = df_trakt[df_trakt['id'].str.contains('|'.join(diffMovies))]\n",
    "            \n",
    "            ## Select data to search in OMDB\n",
    "            data = df_diffMovies[cols]\n",
    "                        \n",
    "    elif not isinstance(foo, pd.core.frame.DataFrame):       \n",
    "        newMovies = len(df_trakt)\n",
    "        ## Select data to search in OMDB\n",
    "        data = df_trakt[cols]\n",
    "        \n",
    "    else:\n",
    "        print('Do nothing.')\n",
    "        \n",
    "    return data, newMovies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date and time from timestamp\n",
    "def from_timestamp(df):\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    # extracting time from timestamp\n",
    "    df['time'] = [dt.datetime.time(d) for d in df['timestamp']]    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new data with existing df from pickle file\n",
    "def look_iama_pickle(foo, df_trakt, api, forceRequest=False):\n",
    "    movies = []\n",
    "    \n",
    "    # Check difference\n",
    "    _, newMovies = check_new_movies(foo, df_trakt)   \n",
    "    \n",
    "    data = df_trakt.iloc[-newMovies:,:] #[['title','id']] # year\n",
    "    \n",
    "    if api == 'omdb':\n",
    "        movies = omdb.request_db(data)\n",
    "    elif api == 'imdb':\n",
    "        movies = imdb.request_db(data)\n",
    "        movies = imdb.clean_df(movies)\n",
    "        \n",
    "    index = data.index     \n",
    "        \n",
    "    # copy foo if pickle exists and there's no new movies\n",
    "    if isinstance(foo, pd.core.frame.DataFrame) and not forceRequest:  \n",
    "        if newMovies == 0:\n",
    "            df = foo.copy()\n",
    "            df['timestamp'] = pd.Series(df_trakt['timestamp'])\n",
    "            \n",
    "        else: # newMovies != 0\n",
    "            df_movies = pd.DataFrame(movies)\n",
    "            df_movies.columns = [x.lower() for x in df_movies.columns]\n",
    "\n",
    "            df_movies = df_movies.tail(newMovies).reset_index(drop=True)\n",
    "            \n",
    "            index = index[-newMovies:]\n",
    "            df_movies['timestamp'] = pd.Series(df_trakt.iloc[index].reset_index()['timestamp']) \n",
    "            df_movies = from_timestamp(df_movies)     \n",
    "            \n",
    "            df = foo.append(df_movies)\n",
    "    \n",
    "    elif not isinstance(foo, pd.core.frame.DataFrame) or forceRequest:\n",
    "        df = pd.DataFrame(movies)\n",
    "        # use OMDB query result and convert to dataframe\n",
    "        df['timestamp'] = pd.Series(df_trakt['timestamp'])\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "        \n",
    "        df = from_timestamp(df)\n",
    "    \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single movie hard correct\n",
    "def hard_correct_movie_data(df, loc, idt, api):\n",
    "    temp = []\n",
    "    response = []\n",
    "    \n",
    "    if api == 'omdb':\n",
    "        if 'Error' in df.columns:\n",
    "            df.drop('Error', axis=1, inplace=True)\n",
    "        \n",
    "        response = requests.get(data_URL, params={'type':'movie', 'i':idt}).json()\n",
    "        temp.append(response)\n",
    "        \n",
    "        sel_cols = all_cols[:-4] # up until 'Response' - no 'Timestamp'\n",
    "        correct = pd.DataFrame(temp)[sel_cols]\n",
    "        df.loc[loc, sel_cols] = correct.loc[0] # only\n",
    "    \n",
    "    elif api == 'imdb':\n",
    "        idt = idt.replace(r'tt', '')\n",
    "        ia = IMDb()\n",
    "        response = ia.get_movie(idt, info='main')\n",
    "        temp.append({key: response.get(key) for key in cols_imdb})\n",
    "\n",
    "        correct = imdb.clean_df(temp)\n",
    "        df.iloc[loc, :] = correct.loc[0]\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get days per month/per year without a movie watched\n",
    "def skip_days(df, calendar, year):\n",
    "    # explode df\n",
    "    df_explode = explode_date(df)\n",
    "    # filter by year\n",
    "    df_explode = df_explode[df_explode['Date'].dt.year == year]\n",
    "    # crosstab days by month\n",
    "    df_explode = pd.crosstab(df_explode['Day'], [df_explode['Month'], df_explode['MonthName']])\n",
    "    \n",
    "    # get months\n",
    "    col_index = df_explode.columns\n",
    "       \n",
    "    # get days in month of complete months in year\n",
    "    calyear = calendar[calendar.date.dt.year == year].reset_index(drop=True)\n",
    "    days_in_months = calyear.daysinmonths\n",
    "    \n",
    "    # months complete this year\n",
    "    months = len(calyear)\n",
    "    \n",
    "    # initialize\n",
    "    no_moviedays = []\n",
    "    pct_no_moviedays = 0\n",
    "    \n",
    "    for i in range(months):\n",
    "        moviedays = 0\n",
    "        # sum all days per month with 0 - False (no movies watched)\n",
    "        moviedays = df_explode[col_index[i]].astype(bool).sum(axis=0)\n",
    "        # append sum to array (sum per month)\n",
    "        no_moviedays.append(int(days_in_months[i] - moviedays))\n",
    "    \n",
    "    # Percentage of days per year without a movie watched\n",
    "    if days_in_months.sum() != 0:\n",
    "        pct_no_moviedays = int((sum(no_moviedays) / days_in_months.sum()) * 100)\n",
    "    else:\n",
    "        pct_no_moviedays = 0\n",
    "        \n",
    "    print(str(year))\n",
    "    print('By month: ' + str(no_moviedays))\n",
    "    print('Total: ' + str(sum(no_moviedays)) + '/' + str(calyear.daysinmonths.sum()))\n",
    "    print(str(pct_no_moviedays) + ' %')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create crosstab filtering by year\n",
    "def crosstab_by_year(df, index=None, year=None):\n",
    "    # if year=None get all years\n",
    "    cols = ['Title','Date']\n",
    "    \n",
    "    if year != None:\n",
    "        df_ = df[df['Date'].dt.year == year][cols].copy()\n",
    "    else:\n",
    "        df_ = df[cols].copy()\n",
    "    \n",
    "    df_ = explode_date(df_)\n",
    "    if index == None:\n",
    "        # Movies by month/year\n",
    "        multiIndex = df_['DateYear']\n",
    "    else:\n",
    "        multiIndex = [df_[index], df_[index+'Name']]\n",
    "    \n",
    "    if index == 'Weekday' or index == None:\n",
    "        ct = pd.crosstab(multiIndex, [df_['Month'], df_['MonthName']], margins=True)\n",
    "    elif index == 'Month':\n",
    "        ct = pd.crosstab(multiIndex, df_['Day'])\n",
    "    \n",
    "    return ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movie ratio by movies watched on weekends vs movies watched on weekdays\n",
    "def ratio_weekend(df, year=None):    \n",
    "    df_ = create_weekday_df(df, year)\n",
    "\n",
    "    # Create Weekdays df with weekdays' names\n",
    "    allweek = df_.Weekday.values #['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']    \n",
    "    df_week = pd.DataFrame(0, index=allweek, columns=['Movies'])    \n",
    "    df_week.reset_index(inplace=True)\n",
    "    df_week.rename(columns={\"index\": \"Weekday\"}, inplace=True)\n",
    "\n",
    "    # Concatenate dfs\n",
    "    df_concat = pd.concat([df_week, df_]).groupby(['Weekday']).sum().reset_index()\n",
    "    df_concat = df_concat.set_index('Weekday').loc[allweek]\n",
    "\n",
    "    # Weekdays vs Weekend\n",
    "    dropdays = allweek[1:-1] # ['Tuesday','Wednesday','Thursday','Friday','Saturday']\n",
    "    # weekdays sum\n",
    "    df_concat.loc['Monday'] += df_concat.iloc[1:5].sum()\n",
    "    # weekend sum\n",
    "    df_concat.loc['Sunday'] += df_concat.iloc[5].sum()\n",
    "    # drop unecessary columns\n",
    "    df_concat.drop(dropdays, inplace=True)\n",
    "    # rename columns\n",
    "    df_concat.rename(index={'Monday': 'Weekdays'}, inplace=True)\n",
    "    df_concat.rename(index={'Sunday': 'Weekend'}, inplace=True)\n",
    "    \n",
    "    # Get ratio\n",
    "    ratio = df_concat.reset_index()['Movies']\n",
    "    pct_ratio = ((ratio.iloc[1] / (ratio.iloc[0] + ratio.iloc[1])) * 100).astype(int)    \n",
    "    print(str(pct_ratio) + '% of the movies were watched on the weekend!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of string\n",
    "def counter_display(df, by, col, TOP=None):\n",
    "    # Check type\n",
    "    sample = df[by].sample().values[0]\n",
    "    \n",
    "    if isinstance(sample, str):\n",
    "        series = df[by].str.split(', ').apply(lambda x: [e.strip() for e in x])\n",
    "        # Remove duplicates\n",
    "        series = series.map(lambda x: list(set(x)))\n",
    "        series = pd.Series(series.map(Counter).sum())\n",
    "\n",
    "    else: # list\n",
    "        series = pd.Series(df[by].value_counts())\n",
    "           \n",
    "    # Organize df to export\n",
    "    df_export = pd.DataFrame(series, columns=[col])\n",
    "    \n",
    "    if TOP == None:\n",
    "        # Everything\n",
    "        df_export = df_export.sort_values(by=col, ascending=False)\n",
    "    else:\n",
    "        # Show TOP\n",
    "        df_export = df_export.nlargest(TOP, col, keep='all')\n",
    "   \n",
    "    return df_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average movie rating by column\n",
    "# If column values have multiple substrings in a string (examples: 'Genre', 'Actors', etc) use explode() to separate all values\n",
    "def get_mean_value(df, by, get_avg, TOP=None):   \n",
    "    # Create df to explode by 'by'\n",
    "    df_explode = df.copy() # remove some not needed columns\n",
    "    # Split multiple persons in one string\n",
    "    df_explode[by] = df_explode[by].str.split(', ').apply(lambda x: [e.strip() for e in x])\n",
    "\n",
    "    # Remove duplicates\n",
    "    df_explode[by] = df_explode[by].map(lambda x: list(set(x)))\n",
    "    \n",
    "    # Explode df base on 'by'\n",
    "    df_explode = explode(df_explode, [by])\n",
    "    \n",
    "    df_export = df_explode.groupby(by).agg({'Title':['count','; '.join], get_avg:'mean'})\n",
    "    df_export = df_export.droplevel(0, axis=1)\n",
    "    df_export = df_export.rename(columns={'join':'Movies', 'count':'Total', 'mean':get_avg})\n",
    "    \n",
    "    # if 'imdbRating'\n",
    "    if get_avg.find('Rating') != -1:\n",
    "        df_export[get_avg] = round(df_export[get_avg], 2)\n",
    "    # else 'Runtime' or 'imdbVotes'\n",
    "    else:\n",
    "        df_export[get_avg] = df_export[get_avg].astype(int)\n",
    "         \n",
    "    if TOP == None:\n",
    "        # Everything\n",
    "        df_export = df_export.sort_values('Total', ascending=False)\n",
    "    else:\n",
    "        # Show TOP\n",
    "        df_export = df_export.nlargest(TOP, 'Total', keep='all')\n",
    "    \n",
    "    return df_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movies by actor\n",
    "def count_actor(series, TOP):     \n",
    "    seriesNew = []\n",
    "    \n",
    "    for i in range(len(series)):\n",
    "        # initialize an empty string\n",
    "        series.iloc[i]\n",
    "        str1 = ', ' .join(series.iloc[i])\n",
    "        seriesNew.append(Counter([x.strip() for x in str1.split(',')]).most_common(TOP))\n",
    "                      \n",
    "    return pd.Series(seriesNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair director - actor\n",
    "def director_actors(data, col, TOP):\n",
    "    colList = counter_display(data, col, 'Actors', None).reset_index()['index']\n",
    "    d = {}\n",
    "\n",
    "    for i in range(len(colList)):\n",
    "        value = colList[i]        \n",
    "        d[value] = [data[data[col].str.contains(colList[i])]['Actors'].values]\n",
    "\n",
    "    data_export = pd.DataFrame.from_dict(d, orient='index', columns=['Actors']).head(TOP)\n",
    "    \n",
    "    return data_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check movies per day\n",
    "def movies_per_day(df, year):    \n",
    "    nMovies = df.loc[year]['Title']\n",
    "\n",
    "    now = pd.Timestamp('now')\n",
    "    if year == now.year:\n",
    "        lastDay = date.today()\n",
    "    else:\n",
    "        lastDay = date(year, 12, 31)\n",
    "    \n",
    "    firstDay = date(year, 1, 1)\n",
    "    delta = lastDay - firstDay\n",
    "\n",
    "    moviesPerDay = nMovies / (delta.days + 1) # 1st of January\n",
    "    print(moviesPerDay.round(2), 'movies per day in', year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that computes the weighted rating of each movie\n",
    "def weighted_rating(v, R, m, C):\n",
    "    # v - votes\n",
    "    # R - Rating\n",
    "    # m - minimun number of votes\n",
    "    # C - mean\n",
    "    score = []\n",
    "    # Calculation based on the IMDB formula\n",
    "    score = (v/(v+m) * R) + (m/(m+v) * C).round(3)\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre columns to use in the functions below\n",
    "cols_genre = ['Genre','Title','imdbRating','Date']\n",
    "\n",
    "# Genre with most watched movies\n",
    "def most_watched_genre(df, TOP, year):\n",
    "    df_explode_genre = df[df['Date'].dt.year == year][cols_genre].copy()\n",
    "       \n",
    "    df_explode_genre = split_explode(df_explode_genre, 'Genre')     \n",
    "    df_explode_genrerat = get_mean_value(df_explode_genre, 'Genre', 'imdbRating')\n",
    "    \n",
    "    show_all(df_explode_genrerat.nlargest(TOP, 'Total', keep='all'))\n",
    "    \n",
    "    return df_explode_genrerat\n",
    "\n",
    "\n",
    "# Most watched genre combo\n",
    "def most_watched_genre_combo(df_, TOP, year):\n",
    "    df_genre = df_[df_['Date'].dt.year == year][cols_genre].copy()\n",
    "    \n",
    "    gb_genre = df_genre.groupby(by='Genre')\n",
    "    # Genre combination with most movies, showing worst and best rated movies\n",
    "    df_genre_agg = gb_genre.agg({'imdbRating': ['min','max','mean'], \n",
    "                                 'Title': 'count'})\n",
    "    df_genre_agg.reset_index(inplace=True)\n",
    "    \n",
    "    df_genre_agg_worst = gb_genre['imdbRating'].idxmin().fillna(0).astype(int)\n",
    "    df_genre_agg[('Title','worst')] = df_genre.reindex(df_genre_agg_worst).reset_index(drop=True)['Title']\n",
    "    \n",
    "    df_genre_agg_best = gb_genre['imdbRating'].idxmax().fillna(0).astype(int)\n",
    "    df_genre_agg[('Title','best')] = df_genre.reindex(df_genre_agg_best).reset_index(drop=True)['Title']\n",
    "    \n",
    "    df_genre_agg = df_genre_agg.set_index([('Genre','')]).round(1)\n",
    "    df_genre_agg.index.rename('Genre', inplace=True)\n",
    "    \n",
    "    show_all(df_genre_agg.nlargest(TOP, [('Title','count')], keep='all'))\n",
    "    \n",
    "    return df_genre_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double group showing count, list of movies and average rating\n",
    "def double_group_info(df, col1, col2, TOP=3):   \n",
    "    # Explode columns\n",
    "    cols = [col1, col2]\n",
    "    \n",
    "    for col in cols:\n",
    "        df = split_explode(df, col)\n",
    "    \n",
    "    # Remove top 2 countries from dataframe\n",
    "    list_remove_countries = ['United States','United Kingdom']\n",
    "    if col1 == 'Country':\n",
    "        df = df[~df[col1].isin(list_remove_countries)]\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    # Clean strings\n",
    "    df[col1] = df[col1].apply(lambda x : x.lstrip(' ').rstrip(' '))\n",
    "    df[col2] = df[col2].apply(lambda x : x.lstrip(' ').rstrip(' '))\n",
    "    \n",
    "    # Drop duplicates, for instance, production companies with multiple appearences in same movie\n",
    "    df = df[~df.duplicated()]\n",
    "    \n",
    "    # Group by\n",
    "    gb_df = df.groupby([col1,col2]).agg({'Title':['count','; '.join], 'imdbRating':'mean'})\n",
    "    gb_df[('imdbRating','mean')] = gb_df[('imdbRating','mean')].round(2)\n",
    "    \n",
    "    # Select only cases with more than 1 movie\n",
    "    gb_df = gb_df[gb_df[('Title','count')] > 1]\n",
    "    # Sort values by group\n",
    "    gb_df = gb_df.groupby(level=0, group_keys=False).apply(lambda x: x.sort_values(('Title','count'), ascending=False).nlargest(TOP, ('Title','count'), keep='all')) #.head(TOP))\n",
    "    \n",
    "    #show_all(gb_df)\n",
    "    \n",
    "    return gb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common column values pairing\n",
    "def pairing(df, col, pair=2):\n",
    "    list_ = df[col].apply(lambda x: x.split(','))\n",
    "    list_ = [[x.lstrip().rstrip() for x in l] for l in list_] # strip ' ' from strings\n",
    "    \n",
    "    d  = Counter()\n",
    "    for sub in list_:\n",
    "        if len(list_) < pair:\n",
    "            continue\n",
    "        sub.sort()\n",
    "        for comb in combinations(sub, pair):\n",
    "            d[comb] += 1\n",
    "            \n",
    "    df_pairs = pd.DataFrame.from_dict(d, orient='index').reset_index()\n",
    "    df_pairs.columns = ['Pairs','Count']\n",
    "    df_pairs = df_pairs.set_index('Pairs')\n",
    "    \n",
    "    return df_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common column values pairing\n",
    "def pairing_columns(df, col1, col2, pair=2):\n",
    "    list_ = df[col1].apply(lambda x: x.split(','))\n",
    "    list_ = [[x.lstrip().rstrip() for x in l] for l in list_] # strip ' ' from strings\n",
    "    \n",
    "    d  = Counter()\n",
    "    for sub in list_:\n",
    "        if len(list_) < pair:\n",
    "            continue\n",
    "        sub.sort()\n",
    "        for comb in combinations(sub, pair):\n",
    "            d[comb] += 1\n",
    "            \n",
    "    df_pairs = pd.DataFrame.from_dict(d, orient='index').reset_index()\n",
    "    df_pairs.columns = ['Pairs','Count']\n",
    "    \n",
    "    return df_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set colormap\n",
    "plot_cmap = 'YlGnBu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date related lists\n",
    "days = np.arange(1, 32, 1) # 1 to 31\n",
    "weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display everything\n",
    "def show_all(df):\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add value labels\n",
    "def add_labels(x,y):\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i, y[i], y[i], ha = 'center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical bar plot with x as 'year' \n",
    "def add_ticks_vbarplot(x, y, ax):\n",
    "    bars = ax.bar(x, y, width=0.8)\n",
    "\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        label_x_pos = bar.get_x() + bar.get_width() / 2\n",
    "        ax.text(label_x_pos, height+0.1, s=f'{height}', ha='center', va='bottom')\n",
    "        \n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(9)\n",
    "    \n",
    "    start = min(x)\n",
    "    end = max(x)+1\n",
    "    \n",
    "    #start, end = ax.get_xlim()\n",
    "    ax.xaxis.set_ticks(np.arange(start, end))\n",
    "    ax.tick_params(axis='x', labelsize=10)\n",
    "    ax.set_xticklabels(np.arange(start, end), rotation=90)   \n",
    "    ax.yaxis.get_major_locator().set_params(integer=True)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a heatmap with the numeric values in each cell\n",
    "def plot_heatmap(df, index, year):\n",
    "    DAYS = 31\n",
    "    MONTHS = 12\n",
    "\n",
    "    plotme = crosstab_by_year(df, index, year)\n",
    "    plotme = plotme.droplevel(0, axis=0)\n",
    "\n",
    "    # If less than 12 months, append missing months\n",
    "    if index=='Weekday':\n",
    "        # Drop rows used to organize data and remove 'All'\n",
    "        plotme = plotme.iloc[:-1,:]\n",
    "        plotme = plotme.droplevel(0, axis=1).iloc[:,:-1]\n",
    "        \n",
    "        if len(plotme.columns) < MONTHS:           \n",
    "            # Create df to complement data\n",
    "            df_12months = pd.DataFrame(0, index=plotme.index.values, columns=months[len(plotme.columns):])\n",
    "            plotme = plotme.join(df_12months)\n",
    "            \n",
    "        # Set plot\n",
    "        ylabel = index\n",
    "        _, ax = plt.subplots(figsize=(9,4))\n",
    "        plt.title('Movie ' + ylabel + ' count by Month')\n",
    "        \n",
    "    elif index=='Month':\n",
    "        if len(plotme.index) < MONTHS:\n",
    "            # Create df to complement data\n",
    "            df_12months = pd.DataFrame(0, index=months[len(plotme.index):], columns=plotme.columns.values)\n",
    "            plotme = plotme.append(df_12months)\n",
    "            \n",
    "        # Use days instead of weekdays\n",
    "        plotme = plotme.T\n",
    "\n",
    "        # Add missing days\n",
    "        add_rows = list(set(np.arange(1, DAYS+1, 1)) - set(plotme.index))        \n",
    "        plotme = plotme.append(pd.DataFrame(0, index=add_rows, columns=plotme.columns))\n",
    "        plotme.sort_index(inplace=True)\n",
    "        \n",
    "        # Set plot\n",
    "        ylabel = 'Day'\n",
    "        _, ax = plt.subplots(figsize=(8,15))\n",
    "        plt.title('Movie ' + ylabel + ' count by ' + index)\n",
    "\n",
    "    # Plot\n",
    "    sns.heatmap(plotme, annot=True, fmt=\"d\")\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create week dataframe with total movies watched by weekday\n",
    "def create_weekday_df(df, year):\n",
    "    # Select 'All' column and remove 'All' row\n",
    "    df_weekday = pd.DataFrame(crosstab_by_year(df, 'Weekday', year)[('All','')]).reset_index().iloc[:-1, :] \n",
    "    # Get columns names ('Weekday' and 'WeekdayName')\n",
    "    df_weekday.columns = df_weekday.columns.droplevel(1)    \n",
    "    # Select and rename columns\n",
    "    df_weekday = df_weekday[['WeekdayName','All']]\n",
    "    df_weekday.rename(columns={\"WeekdayName\": \"Weekday\", \"All\": \"Movies\"}, inplace=True)    \n",
    "\n",
    "    return df_weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movies by Weekday\n",
    "def plot_weekday_bar(df, year):    \n",
    "    df_weekday = create_weekday_df(df, year)\n",
    "\n",
    "    # Prepare plot\n",
    "    cmap = plt.get_cmap(plot_cmap)\n",
    "    norm = plt.Normalize(df_weekday['Movies'].min(), df_weekday['Movies'].max())\n",
    "    values = df_weekday['Movies'].values\n",
    "    \n",
    "    # Plotting\n",
    "    ax = plt.figure(figsize=(len(values),6)).gca()\n",
    "    sns.barplot('Weekday', 'Movies', data=df_weekday, palette=cmap(norm(values)))\n",
    "    \n",
    "    ax.yaxis.get_major_locator().set_params(integer=True)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 90) \n",
    "\n",
    "    plt.title('# Movies watched by Weekday')\n",
    "    plt.ylabel('# Movies')\n",
    "    \n",
    "    for i, n in enumerate(df_weekday['Movies']):\n",
    "        plt.text(i, n+0.3, n, fontdict={'fontsize':12})\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Plot ratio\n",
    "    ratio_weekend(df, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movies by Week of Year\n",
    "def plot_week_bar(df, year):  \n",
    "    NWEEKS = 52\n",
    "    nweeks = np.arange(1, NWEEKS+1, 1)\n",
    "    \n",
    "    df_woy = df[['Title','Date']].copy()\n",
    "    df_woy['Weekofyear'] = df_woy['Date'].dt.weekofyear\n",
    "    \n",
    "    # No movies from week 53 in the beginning of the year\n",
    "    temp = df_woy[df_woy['Date'].dt.year == year]\n",
    "    temp = temp[~((temp['Date'].dt.month == 1) & (temp['Date'].dt.weekofyear >= NWEEKS))]\n",
    "    \n",
    "    # Week starts on monday and some values may fall on week 52 or 53 of previous year\n",
    "    if df_woy[df_woy['Date'].dt.year == year+1].size > 0:\n",
    "        appendthis = df_woy[df_woy['Date'].dt.year == year+1][df_woy['Date'].dt.weekofyear >= NWEEKS]\n",
    "        temp = temp.append(appendthis)\n",
    "        \n",
    "    # Group by\n",
    "    df_woy = temp.copy()\n",
    "    gb_woy = df_woy.groupby('Weekofyear').agg({'Title':'count'}).reset_index()\n",
    "    \n",
    "    # If not all weeks of year present, add them\n",
    "    add_rows = list(set(nweeks) - set(gb_woy.Weekofyear))\n",
    "    gb_woy = gb_woy.append(pd.DataFrame({'Weekofyear': add_rows, 'Title': 0}))\n",
    "    gb_woy.sort_values('Weekofyear', inplace=True)\n",
    "\n",
    "    # Prepare plot\n",
    "    cmap = plt.get_cmap(plot_cmap)\n",
    "    norm = plt.Normalize(gb_woy['Title'].min(), gb_woy['Title'].max())\n",
    "    values = gb_woy['Title'].values\n",
    "    \n",
    "    gb_woy.Weekofyear = gb_woy.Weekofyear.astype(int)\n",
    "    gb_woy.rename(columns={'Title':'# Movies'}, inplace=True)\n",
    "    \n",
    "    # Plotting     \n",
    "    plotme = gb_woy.set_index('Weekofyear').T\n",
    "    xsize = NWEEKS // 2\n",
    "    plt.figure(figsize=(xsize, 2))\n",
    "    sns.heatmap(plotme, annot=True, fmt=\"d\", cbar_kws={\"orientation\": \"horizontal\", \"pad\": 0.5})\n",
    "    \n",
    "    plt.title('# Movies watched by Week of Year (in ' + str(year) +')')\n",
    "    plt.xlabel('Week of Year')\n",
    "    #plt.ylabel('# Movies') \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot how many hours spent watching movies by month\n",
    "def plot_hour_month_bar(df, year):\n",
    "    # Group by month (get .month to maintain month order)\n",
    "    group_month = [df['Date'].dt.month, df['Date'].dt.month_name()]\n",
    "    \n",
    "    df_month = df[df['Date'].dt.year==year].groupby(group_month).agg({'Runtime':'sum'}).droplevel(0, axis=0).reset_index()\n",
    "    df_month['Runtime'] = (df_month['Runtime'] / 60).astype(int)\n",
    "    df_month = df_month.rename(columns={'Date':'Month'})\n",
    "\n",
    "    # If less than 12 months, append missing months\n",
    "    if len(df_month) < len(months):\n",
    "        df_12months = pd.DataFrame({'Month':months, 'Runtime':0})\n",
    "        df_month = df_month.append(df_12months.iloc[len(df_month):,:])\n",
    "    \n",
    "    # Prepare plot\n",
    "    cmap = plt.get_cmap(plot_cmap)\n",
    "    norm = plt.Normalize(df_month.Runtime.min(), df_month.Runtime.max())\n",
    "    values = df_month.Runtime.values\n",
    "\n",
    "    # Plotting\n",
    "    ax = plt.figure(figsize=(len(months),6)).gca()\n",
    "    sns.barplot(x='Month', y='Runtime',data=df_month, palette=cmap(norm(values)))\n",
    "    \n",
    "    ax.yaxis.get_major_locator().set_params(integer=True)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 90) \n",
    "    \n",
    "    plt.title('# Hours of movies watched by Month (in ' + str(year) +')')\n",
    "    plt.ylabel('# Hours')\n",
    "    \n",
    "    for i, n in enumerate(values):\n",
    "        plt.text(i, n+0.1, n, fontdict={'fontsize':12})\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot swarm box plot with x based on Release Year or Decade\n",
    "def plot_box_swarm(x, y, data, order):\n",
    "    # Plot\n",
    "    xsize = len(order)\n",
    "    \n",
    "    _, ax = plt.subplots(figsize=(xsize, 6))\n",
    "    ax = sns.boxplot(x, y, data=data, order=order)\n",
    "    ax = sns.swarmplot(x, y, data=data, order=order, color=\".4\")\n",
    "    \n",
    "    # add grid lines\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.xaxis.grid(True)\n",
    "   \n",
    "    if x == 'Year':\n",
    "        x = 'Release Year'\n",
    "        ax.set_xlabel(x)\n",
    "        \n",
    "    title = y + ' by ' + x    \n",
    "    ax.set_title(title)    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 90) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of Movies by Release Year\n",
    "def plot_movie_trend(df, year=None):\n",
    "    if year is not None:\n",
    "        plot_movies_year = df[df['Date'].dt.year == year].groupby(by='Year').agg({'Title': 'count'}).reset_index()\n",
    "    else:\n",
    "        plot_movies_year = df.copy()\n",
    "        \n",
    "    x = plot_movies_year['Year']\n",
    "    y = plot_movies_year['Title']\n",
    "    \n",
    "    # Plot\n",
    "    # https://towardsdatascience.com/how-to-make-bar-and-hbar-charts-with-labels-using-matplotlib-b701ce70ba9c   \n",
    "    _, ax = plt.subplots(figsize=(30, 6))\n",
    "    add_ticks_vbarplot(x, y, ax)     \n",
    "    \n",
    "    if year is not None:\n",
    "        plt.title('# Movies watched by Release Year (in ' + str(year) +')')\n",
    "    else:\n",
    "        plt.title('# Movies watched by Release Year')\n",
    "        \n",
    "    plt.xlabel('Release Year')\n",
    "    plt.ylabel('# Movies')\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
